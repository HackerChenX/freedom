#!/usr/bin/env python3
"""
é‡æ–°ç”Ÿæˆä¹°ç‚¹åˆ†ææŠ¥å‘Šè„šæœ¬

è¯¥è„šæœ¬ç”¨äºé‡æ–°ç”Ÿæˆä¼˜åŒ–åçš„ä¹°ç‚¹å…±æ€§æŒ‡æ ‡åˆ†ææŠ¥å‘Šï¼Œä¿®å¤å‘½ä¸­ç‡è®¡ç®—é”™è¯¯å¹¶æå‡æŠ¥å‘Šè´¨é‡ã€‚
"""

import os
import sys
import json
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
root_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, root_dir)

from utils.logger import get_logger
from analysis.buypoints.buypoint_batch_analyzer import BuyPointBatchAnalyzer

logger = get_logger(__name__)

def load_analysis_results(results_file: str):
    """åŠ è½½åˆ†æç»“æœ"""
    try:
        with open(results_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        logger.error(f"åŠ è½½åˆ†æç»“æœå¤±è´¥: {e}")
        return []

def regenerate_report():
    """é‡æ–°ç”Ÿæˆä¹°ç‚¹åˆ†ææŠ¥å‘Š"""
    try:
        # è®¾ç½®è·¯å¾„
        results_dir = "data/result/zxm_methods_fix_test"
        results_file = os.path.join(results_dir, "analysis_results.json")
        report_file = os.path.join(results_dir, "common_indicators_report.md")
        
        # æ£€æŸ¥ç»“æœæ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(results_file):
            logger.error(f"åˆ†æç»“æœæ–‡ä»¶ä¸å­˜åœ¨: {results_file}")
            return
        
        # åŠ è½½åˆ†æç»“æœ
        logger.info("åŠ è½½åˆ†æç»“æœ...")
        analysis_results = load_analysis_results(results_file)
        
        if not analysis_results:
            logger.error("åˆ†æç»“æœä¸ºç©º")
            return
        
        logger.info(f"åŠ è½½äº† {len(analysis_results)} ä¸ªä¹°ç‚¹åˆ†æç»“æœ")
        
        # åˆ›å»ºæ‰¹é‡åˆ†æå™¨
        analyzer = BuyPointBatchAnalyzer()
        
        # æå–å…±æ€§æŒ‡æ ‡
        logger.info("æå–å…±æ€§æŒ‡æ ‡...")
        common_indicators = analyzer.extract_common_indicators(
            buypoint_results=analysis_results,
            min_hit_ratio=0.3  # é™ä½é˜ˆå€¼ä»¥è·å–æ›´å¤šæŒ‡æ ‡
        )
        
        if not common_indicators:
            logger.warning("æœªèƒ½æå–åˆ°å…±æ€§æŒ‡æ ‡")
            return
        
        # ç»Ÿè®¡ä¿¡æ¯
        total_indicators = sum(len(indicators) for indicators in common_indicators.values())
        logger.info(f"æå–åˆ° {len(common_indicators)} ä¸ªå‘¨æœŸçš„å…±æ€§æŒ‡æ ‡ï¼Œå…± {total_indicators} ä¸ªæŒ‡æ ‡å½¢æ€")
        
        # ç”Ÿæˆä¼˜åŒ–åçš„æŠ¥å‘Š
        logger.info("ç”Ÿæˆä¼˜åŒ–åçš„æŠ¥å‘Š...")
        analyzer._generate_indicators_report(common_indicators, report_file)
        
        logger.info(f"æŠ¥å‘Šå·²ç”Ÿæˆ: {report_file}")
        
        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        print("\n" + "="*60)
        print("ğŸ“Š æŠ¥å‘Šç”Ÿæˆå®Œæˆ")
        print("="*60)
        print(f"ğŸ“ æŠ¥å‘Šæ–‡ä»¶: {report_file}")
        print(f"ğŸ“ˆ åˆ†æå‘¨æœŸ: {len(common_indicators)} ä¸ª")
        print(f"ğŸ“Š å…±æ€§æŒ‡æ ‡: {total_indicators} ä¸ª")
        print(f"ğŸ•’ ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        # æ˜¾ç¤ºå„å‘¨æœŸçš„æŒ‡æ ‡æ•°é‡
        print(f"\nğŸ“‹ å„å‘¨æœŸæŒ‡æ ‡ç»Ÿè®¡:")
        for period, indicators in common_indicators.items():
            print(f"  â€¢ {period}: {len(indicators)} ä¸ªæŒ‡æ ‡")
        
        print("\nâœ… ä¼˜åŒ–å†…å®¹:")
        print("  â€¢ ä¿®å¤äº†å‘½ä¸­ç‡è®¡ç®—é”™è¯¯ï¼ˆé™åˆ¶åœ¨0-100%ï¼‰")
        print("  â€¢ é‡æ–°è®¡ç®—å¹³å‡å¾—åˆ†ï¼ˆå¤„ç†0åˆ†é—®é¢˜ï¼‰")
        print("  â€¢ æ·»åŠ äº†è¯¦ç»†çš„åˆ†æè¯´æ˜å’Œåº”ç”¨å»ºè®®")
        print("  â€¢ ä¼˜åŒ–äº†è¡¨æ ¼æ’åºï¼ˆæŒ‰å‘½ä¸­ç‡å’Œå¾—åˆ†ï¼‰")
        print("  â€¢ å¢åŠ äº†ç³»ç»Ÿæ€§èƒ½å’ŒæŠ€æœ¯æ”¯æŒä¿¡æ¯")
        
    except Exception as e:
        logger.error(f"é‡æ–°ç”ŸæˆæŠ¥å‘Šæ—¶å‡ºé”™: {e}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹é‡æ–°ç”Ÿæˆä¹°ç‚¹åˆ†ææŠ¥å‘Š...")
    print("ğŸ“‹ ä¼˜åŒ–ç›®æ ‡:")
    print("  1. ä¿®å¤å‘½ä¸­ç‡è®¡ç®—é”™è¯¯")
    print("  2. é‡æ–°è®¡ç®—å¹³å‡å¾—åˆ†")
    print("  3. æ·»åŠ è¯¦ç»†åˆ†æè¯´æ˜")
    print("  4. æå‡æŠ¥å‘Šå¯è¯»æ€§")
    print()
    
    regenerate_report()

if __name__ == "__main__":
    main()
