# 可配置选股系统性能测试计划

## 1. 性能测试目标

本性能测试计划旨在评估可配置选股系统在不同负载和场景下的性能表现，确保系统满足预期的性能指标。主要测试目标包括：

1. 评估系统在不同数据规模下的响应时间
2. 测量系统在高负载下的吞吐量和资源使用情况
3. 确定系统的性能瓶颈和扩展性限制
4. 验证缓存机制的有效性和性能提升
5. 测试多线程处理的效率和资源利用情况
6. 确保系统在长时间运行下的稳定性

## 2. 性能指标

### 2.1 响应时间

| 场景 | 目标值 | 可接受阈值 | 测量方法 |
|------|--------|-----------|--------|
| 小规模选股（100支股票） | < 3秒 | < 5秒 | 测量执行时间 |
| 中规模选股（500支股票） | < 10秒 | < 15秒 | 测量执行时间 |
| 大规模选股（2000支股票） | < 30秒 | < 45秒 | 测量执行时间 |
| 复杂策略执行（多指标多周期） | < 15秒 | < 25秒 | 测量执行时间 |
| 缓存命中查询 | < 0.5秒 | < 1秒 | 测量执行时间 |

### 2.2 吞吐量

| 场景 | 目标值 | 可接受阈值 | 测量方法 |
|------|--------|-----------|--------|
| 单线程选股 | > 20股票/秒 | > 10股票/秒 | 股票数量/执行时间 |
| 多线程选股（4线程） | > 60股票/秒 | > 40股票/秒 | 股票数量/执行时间 |
| 多线程选股（8线程） | > 100股票/秒 | > 80股票/秒 | 股票数量/执行时间 |
| 批量策略执行 | > 5策略/分钟 | > 3策略/分钟 | 策略数量/执行时间 |

### 2.3 资源使用

| 资源 | 目标值 | 可接受阈值 | 测量方法 |
|------|--------|-----------|--------|
| CPU使用率 | < 70% | < 85% | 系统监控工具 |
| 内存使用 | < 2GB | < 4GB | 系统监控工具 |
| 磁盘I/O | < 50MB/s | < 100MB/s | 系统监控工具 |
| 数据库连接数 | < 20 | < 30 | 数据库监控 |
| 缓存大小 | < 1GB | < 2GB | 内存分析工具 |

### 2.4 可扩展性

| 指标 | 目标值 | 可接受阈值 | 测量方法 |
|------|--------|-----------|--------|
| 线程扩展效率（4线程/1线程） | > 3.0 | > 2.5 | 性能比率 |
| 线程扩展效率（8线程/4线程） | > 1.5 | > 1.2 | 性能比率 |
| 数据规模扩展性（响应时间增长） | 线性 | 亚指数级 | 曲线分析 |

### 2.5 稳定性

| 指标 | 目标值 | 可接受阈值 | 测量方法 |
|------|--------|-----------|--------|
| 24小时持续运行 | 无错误 | 非致命错误<2次 | 长时间测试 |
| 内存泄漏 | 无增长 | <10%增长/24小时 | 内存监控 |
| 重复执行一致性 | 100%一致 | >95%一致 | 结果比对 |

## 3. 测试环境

### 3.1 硬件环境

| 配置项 | 测试环境 | 生产环境 |
|--------|---------|---------|
| CPU | 8核心 | 16核心 |
| 内存 | 16GB | 32GB |
| 存储 | SSD 256GB | SSD 512GB |
| 网络 | 1Gbps | 10Gbps |

### 3.2 软件环境

| 配置项 | 版本/设置 |
|--------|----------|
| 操作系统 | Ubuntu 20.04 LTS |
| Python | 3.8.10 |
| ClickHouse | 21.3.10.1 |
| 依赖包 | requirements.txt中指定的版本 |
| 缓存配置 | 启用，最大大小=1GB |
| 线程池大小 | 可变（1-16） |

### 3.3 测试数据

| 数据集 | 描述 | 大小 |
|--------|------|------|
| 小规模数据集 | 100支股票，1年K线数据 | ~50MB |
| 中规模数据集 | 500支股票，2年K线数据 | ~500MB |
| 大规模数据集 | 2000支股票，3年K线数据 | ~4GB |
| 极限数据集 | 5000支股票，5年K线数据 | ~20GB |

### 3.4 监控工具

1. Python `cProfile` - 代码性能分析
2. `memory_profiler` - 内存使用分析
3. `psutil` - 系统资源监控
4. ClickHouse内置监控 - 数据库性能
5. 自定义性能监控装饰器
6. 性能日志记录和分析工具

## 4. 测试场景

### 4.1 基准性能测试

| 测试ID | 测试名称 | 测试描述 | 负载参数 |
|--------|---------|---------|---------|
| PT-B-001 | 小规模选股基准测试 | 使用简单策略在小规模数据上进行选股 | 100支股票，简单策略 |
| PT-B-002 | 中规模选股基准测试 | 使用简单策略在中规模数据上进行选股 | 500支股票，简单策略 |
| PT-B-003 | 大规模选股基准测试 | 使用简单策略在大规模数据上进行选股 | 2000支股票，简单策略 |
| PT-B-004 | 简单策略执行基准 | 测量简单策略执行时间 | 500支股票，单一指标条件 |
| PT-B-005 | 复杂策略执行基准 | 测量复杂策略执行时间 | 500支股票，多指标多周期条件 |

### 4.2 缓存性能测试

| 测试ID | 测试名称 | 测试描述 | 负载参数 |
|--------|---------|---------|---------|
| PT-C-001 | 无缓存基准测试 | 禁用缓存的选股性能 | 500支股票，缓存禁用 |
| PT-C-002 | 有缓存基准测试 | 启用缓存的选股性能 | 500支股票，缓存启用 |
| PT-C-003 | 缓存预热测试 | 测试缓存预热后的性能 | 500支股票，预热缓存 |
| PT-C-004 | 缓存命中率测试 | 测量不同场景下的缓存命中率 | 多次执行相同策略 |
| PT-C-005 | 缓存过期测试 | 测试缓存过期对性能的影响 | 缓存超时设置 |

### 4.3 多线程性能测试

| 测试ID | 测试名称 | 测试描述 | 负载参数 |
|--------|---------|---------|---------|
| PT-M-001 | 单线程基准测试 | 单线程执行性能基准 | 1000支股票，单线程 |
| PT-M-002 | 2线程性能测试 | 2线程并行执行性能 | 1000支股票，2线程 |
| PT-M-003 | 4线程性能测试 | 4线程并行执行性能 | 1000支股票，4线程 |
| PT-M-004 | 8线程性能测试 | 8线程并行执行性能 | 1000支股票，8线程 |
| PT-M-005 | 16线程性能测试 | 16线程并行执行性能 | 1000支股票，16线程 |
| PT-M-006 | 线程饱和测试 | 测试线程数超过CPU核心数的性能 | 1000支股票，32线程 |

### 4.4 负载性能测试

| 测试ID | 测试名称 | 测试描述 | 负载参数 |
|--------|---------|---------|---------|
| PT-L-001 | 数据规模扩展测试 | 测试不同数据规模下的性能变化 | 100/500/1000/2000/5000支股票 |
| PT-L-002 | 策略复杂度扩展测试 | 测试不同策略复杂度下的性能变化 | 1/3/5/10个指标条件 |
| PT-L-003 | 时间范围扩展测试 | 测试不同时间范围数据的性能变化 | 1/2/3/5年K线数据 |
| PT-L-004 | 并发请求测试 | 测试多个同时执行的选股请求 | 2/5/10个并发请求 |
| PT-L-005 | 数据库负载测试 | 测试数据库高负载下的系统性能 | 数据库CPU使用率>80% |

### 4.5 稳定性测试

| 测试ID | 测试名称 | 测试描述 | 负载参数 |
|--------|---------|---------|---------|
| PT-S-001 | 持续运行测试 | 系统连续运行24小时的稳定性 | 每10分钟执行一次选股 |
| PT-S-002 | 内存泄漏测试 | 长时间运行下的内存使用监控 | 重复执行1000次 |
| PT-S-003 | 错误恢复测试 | 系统从错误中恢复的能力测试 | 注入错误后继续执行 |
| PT-S-004 | 资源竞争测试 | 多个进程竞争资源的性能 | 同时运行多个测试进程 |
| PT-S-005 | 数据库连接恢复测试 | 数据库连接中断后恢复测试 | 模拟数据库连接失败 |

## 5. 测试方法

### 5.1 测试执行流程

1. **准备阶段**
   - 设置测试环境和配置
   - 准备测试数据和数据库
   - 初始化性能监控工具
   - 清理缓存和历史数据

2. **执行阶段**
   - 运行基准测试获取基础性能数据
   - 根据测试计划执行各项性能测试
   - 收集性能指标和资源使用数据
   - 记录测试结果和异常情况

3. **分析阶段**
   - 处理收集的性能数据
   - 生成性能图表和报告
   - 与基准性能和目标指标比较
   - 分析性能瓶颈和优化机会

### 5.2 性能指标收集

1. **响应时间**
   - 使用Python `time.time()`测量执行时间
   - 记录每个操作的开始和结束时间
   - 计算平均、最小、最大和百分位响应时间

2. **吞吐量**
   - 记录单位时间内处理的请求数或股票数
   - 计算不同负载下的吞吐量变化
   - 绘制吞吐量与负载的关系图

3. **资源使用**
   - 使用`psutil`监控CPU使用率
   - 使用`memory_profiler`监控内存使用
   - 记录数据库连接数和查询执行时间
   - 监控磁盘I/O和网络带宽使用

4. **扩展性指标**
   - 计算线程增加带来的性能提升比例
   - 分析数据规模增长与响应时间的关系
   - 评估系统在不同负载下的资源利用效率

### 5.3 结果分析方法

1. **性能趋势分析**
   - 绘制响应时间随负载变化的曲线
   - 分析吞吐量随线程数变化的关系
   - 评估资源使用随时间的变化趋势

2. **瓶颈分析**
   - 使用`cProfile`识别代码中的性能热点
   - 分析资源使用峰值和限制因素
   - 评估数据库查询和缓存效率

3. **比较分析**
   - 与基准性能和历史数据比较
   - 评估不同优化措施的效果
   - 与性能目标进行对比分析

## 6. 测试脚本

### 6.1 基准测试脚本

```python
# tests/performance/test_baseline.py
import time
import pandas as pd
from strategy.strategy_executor import StrategyExecutor
from tests.test_data_factory import TestDataFactory

def test_baseline_performance():
    """基准性能测试"""
    # 准备测试数据
    stock_list = TestDataFactory.create_stock_list(count=500)
    strategy_config = TestDataFactory.create_strategy_config("基准测试策略")
    
    # 初始化执行器
    executor = StrategyExecutor()
    
    # 测量执行时间
    start_time = time.time()
    result = executor.execute_strategy(strategy_config)
    execution_time = time.time() - start_time
    
    # 记录性能指标
    throughput = len(stock_list) / execution_time
    
    # 返回性能数据
    return {
        "test_name": "基准性能测试",
        "stock_count": len(stock_list),
        "execution_time": execution_time,
        "throughput": throughput,
        "result_count": len(result)
    }
```

### 6.2 缓存测试脚本

```python
# tests/performance/test_cache.py
import time
import pandas as pd
from strategy.strategy_executor import StrategyExecutor
from db.data_manager import DataManager
from tests.test_data_factory import TestDataFactory

def test_cache_performance():
    """缓存性能测试"""
    # 准备测试数据
    stock_list = TestDataFactory.create_stock_list(count=500)
    strategy_config = TestDataFactory.create_strategy_config("缓存测试策略")
    
    # 清除缓存
    data_manager = DataManager()
    data_manager.clear_cache()
    
    # 初始化执行器
    executor = StrategyExecutor()
    
    # 第一次执行（无缓存）
    start_time = time.time()
    result1 = executor.execute_strategy(strategy_config)
    no_cache_time = time.time() - start_time
    
    # 第二次执行（有缓存）
    start_time = time.time()
    result2 = executor.execute_strategy(strategy_config)
    with_cache_time = time.time() - start_time
    
    # 计算性能提升
    speedup = no_cache_time / with_cache_time if with_cache_time > 0 else float('inf')
    
    # 返回性能数据
    return {
        "test_name": "缓存性能测试",
        "stock_count": len(stock_list),
        "no_cache_time": no_cache_time,
        "with_cache_time": with_cache_time,
        "speedup": speedup,
        "cache_stats": data_manager.get_cache_stats()
    }
```

### 6.3 多线程测试脚本

```python
# tests/performance/test_multithreading.py
import time
import pandas as pd
from strategy.strategy_executor import StrategyExecutor
from tests.test_data_factory import TestDataFactory

def test_multithreading_performance():
    """多线程性能测试"""
    # 准备测试数据
    stock_list = TestDataFactory.create_stock_list(count=1000)
    strategy_config = TestDataFactory.create_strategy_config("多线程测试策略")
    
    # 测试不同线程数
    thread_counts = [1, 2, 4, 8, 16]
    results = []
    
    for thread_count in thread_counts:
        # 初始化执行器
        executor = StrategyExecutor(max_workers=thread_count)
        
        # 测量执行时间
        start_time = time.time()
        result = executor.execute_strategy(strategy_config)
        execution_time = time.time() - start_time
        
        # 记录性能指标
        throughput = len(stock_list) / execution_time
        
        # 添加结果
        results.append({
            "thread_count": thread_count,
            "execution_time": execution_time,
            "throughput": throughput,
            "result_count": len(result)
        })
    
    # 计算扩展性指标
    for i in range(1, len(results)):
        if results[0]["execution_time"] > 0:
            speedup = results[0]["execution_time"] / results[i]["execution_time"]
            efficiency = speedup / results[i]["thread_count"]
            results[i]["speedup"] = speedup
            results[i]["efficiency"] = efficiency
    
    return {
        "test_name": "多线程性能测试",
        "stock_count": len(stock_list),
        "thread_results": results
    }
```

## 7. 测试计划

### 7.1 测试阶段

1. **准备阶段**（1周）
   - 准备测试环境和工具
   - 开发性能测试脚本
   - 创建测试数据集
   - 配置监控和分析工具

2. **基准测试阶段**（1周）
   - 执行基准性能测试
   - 建立性能基准线
   - 确定性能目标和阈值

3. **功能性能测试阶段**（2周）
   - 缓存性能测试
   - 多线程性能测试
   - 负载性能测试

4. **稳定性测试阶段**（1周）
   - 长时间运行测试
   - 错误恢复测试
   - 资源使用监控

5. **分析报告阶段**（1周）
   - 数据整理和分析
   - 性能问题诊断
   - 生成测试报告
   - 提出优化建议

### 7.2 测试日程安排

| 周次 | 主要任务 | 次要任务 | 里程碑 |
|------|---------|---------|--------|
| 第1周 | 准备测试环境和工具 | 开发测试脚本 | 测试环境就绪 |
| 第2周 | 执行基准性能测试 | 分析基准结果 | 性能基准确立 |
| 第3周 | 缓存和多线程测试 | 初步分析结果 | 功能性能数据收集 |
| 第4周 | 负载和扩展性测试 | 持续结果分析 | 功能性能测试完成 |
| 第5周 | 稳定性和长时间测试 | 监控资源使用 | 稳定性测试完成 |
| 第6周 | 数据整理和分析 | 编写测试报告 | 测试报告完成 |

## 8. 测试报告

### 8.1 报告内容

1. **执行摘要**
   - 测试目标和范围
   - 主要发现和结论
   - 性能瓶颈和限制
   - 优化建议

2. **测试结果**
   - 基准性能数据
   - 各测试场景结果
   - 与目标指标比较
   - 问题和异常记录

3. **性能分析**
   - 响应时间和吞吐量分析
   - 资源使用分析
   - 扩展性和稳定性分析
   - 性能瓶颈分析

4. **优化建议**
   - 代码级优化建议
   - 配置优化建议
   - 架构改进建议
   - 资源调整建议

### 8.2 报告格式

1. **HTML报告**
   - 包含交互式图表和表格
   - 支持深入分析和数据过滤
   - 提供性能趋势可视化

2. **PDF报告**
   - 格式化的完整测试报告
   - 包含所有图表和分析结果
   - 适合打印和分享

3. **原始数据**
   - CSV格式的测试数据
   - 用于进一步分析的JSON数据
   - 性能监控日志

## 9. 风险与缓解措施

| 风险 | 影响 | 缓解措施 |
|------|------|---------|
| 测试环境资源不足 | 测试结果不准确 | 使用专用测试服务器，避免资源竞争 |
| 测试数据不代表真实场景 | 性能评估偏差 | 基于真实数据构建测试数据集，覆盖多种场景 |
| 性能波动大 | 难以得出稳定结论 | 多次重复测试取平均值，排除异常值 |
| 测试工具自身影响性能 | 测量干扰 | 最小化监控工具开销，考虑监控影响 |
| 测试时间紧张 | 测试不充分 | 优先测试关键场景，自动化测试流程 |

## 10. 资源需求

1. **人力资源**
   - 1名性能测试工程师
   - 1名开发工程师支持
   - 1名数据分析工程师（兼职）

2. **硬件资源**
   - 专用测试服务器（8核16G）
   - 开发环境（用于测试脚本开发）
   - 数据库服务器

3. **软件资源**
   - 性能监控工具
   - 数据分析工具
   - 测试自动化框架

4. **数据资源**
   - 测试数据集
   - 历史性能数据（如有）
   - 生产环境参考数据

## 11. 总结

本性能测试计划提供了对可配置选股系统进行全面性能评估的框架和方法。通过执行本计划中定义的测试，我们将能够：

1. 了解系统在不同负载下的性能表现
2. 识别系统的性能瓶颈和扩展性限制
3. 验证系统是否满足性能需求
4. 为系统优化提供数据支持和方向

测试结果将帮助我们改进系统性能，提高用户体验，并为未来的扩展和优化提供基础。

## 附录

### A. 性能测试工具配置

```python
# performance_monitor.py 配置示例
PERFORMANCE_MONITOR_CONFIG = {
    "sampling_interval": 0.1,  # 采样间隔（秒）
    "metrics": ["cpu", "memory", "disk", "network"],  # 要监控的指标
    "log_level": "INFO",
    "output_format": "csv",
    "output_dir": "tests/performance/results"
}
```

### B. 测试数据生成脚本

```python
# generate_test_data.py 示例
from tests.test_data_factory import TestDataFactory

# 生成小规模测试数据
TestDataFactory.generate_test_dataset(
    stock_count=100,
    date_range=("2022-01-01", "2022-12-31"),
    output_dir="tests/performance/data/small"
)

# 生成中规模测试数据
TestDataFactory.generate_test_dataset(
    stock_count=500,
    date_range=("2021-01-01", "2022-12-31"),
    output_dir="tests/performance/data/medium"
)

# 生成大规模测试数据
TestDataFactory.generate_test_dataset(
    stock_count=2000,
    date_range=("2020-01-01", "2022-12-31"),
    output_dir="tests/performance/data/large"
)
```

### C. 常见性能问题及解决方案

| 问题类型 | 症状 | 可能原因 | 解决方案 |
|---------|------|---------|---------|
| 响应时间长 | 选股执行时间超过预期 | 低效查询或算法 | 优化SQL查询，增加索引，改进算法 |
| 内存使用高 | 内存持续增长 | 内存泄漏或缓存过大 | 检查对象生命周期，优化缓存策略 |
| CPU瓶颈 | CPU使用率过高 | 计算密集型操作 | 优化算法，使用并行处理，增加缓存 |
| 数据库瓶颈 | 数据库查询时间长 | 缺少索引或查询低效 | 优化查询，增加索引，使用查询缓存 |
| 扩展性差 | 增加线程数性能提升小 | 资源竞争或同步问题 | 减少同步点，优化资源分配 |
| 缓存效率低 | 缓存命中率低 | 缓存策略不当 | 调整缓存键生成策略，优化缓存项大小 | 