#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
ä¹°ç‚¹æ‰¹é‡åˆ†æå™¨

åˆ†æå¤šä¸ªè‚¡ç¥¨ä¹°ç‚¹çš„å…±æ€§æŒ‡æ ‡ç‰¹å¾ï¼Œæå–å…±æ€§æŒ‡æ ‡å¹¶ç”Ÿæˆé€‰è‚¡ç­–ç•¥
"""

import os
import sys
import pandas as pd
import numpy as np
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime
import json
from collections import Counter, defaultdict

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
root_dir = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
sys.path.insert(0, root_dir)

from utils.logger import get_logger
from utils.path_utils import ensure_dir_exists
from analysis.buypoints.period_data_processor import PeriodDataProcessor
from analysis.buypoints.auto_indicator_analyzer import AutoIndicatorAnalyzer
from strategy.strategy_generator import StrategyGenerator
from analysis.validation.buypoint_validator import BuyPointValidator
from analysis.validation.data_quality_validator import DataQualityValidator
from analysis.optimization.strategy_optimizer import StrategyOptimizer
from monitoring.system_monitor import SystemHealthMonitor
from indicators.pattern_registry import PatternRegistry

logger = get_logger(__name__)

# æ‰€æœ‰æŠ€æœ¯æŒ‡æ ‡çš„å½¢æ€å®šä¹‰å·²æˆåŠŸè¿ç§»åˆ°å„è‡ªçš„register_patterns()æ–¹æ³•ä¸­ï¼Œ
# å¹¶æ³¨å†Œåˆ°PatternRegistryã€‚ç³»ç»Ÿç°åœ¨ä½¿ç”¨å®Œå…¨åˆ†æ•£å¼æ¶æ„ï¼Œæ— éœ€é›†ä¸­å¼æ˜ å°„è¡¨ã€‚
#
# å¦‚éœ€æ·»åŠ æ–°çš„æŠ€æœ¯æŒ‡æ ‡å½¢æ€ï¼Œè¯·åœ¨å¯¹åº”çš„æŒ‡æ ‡ç±»ä¸­å®ç°register_patterns()æ–¹æ³•ã€‚


class PatternPolarityFilter:
    """æ¨¡å¼ææ€§è¿‡æ»¤å™¨ - åŸºäºæ³¨å†Œä¿¡æ¯è¿‡æ»¤è´Ÿé¢æ¨¡å¼"""

    def __init__(self):
        from indicators.pattern_registry import PatternRegistry, PatternPolarity
        self.registry = PatternRegistry()
        self.polarity_enum = PatternPolarity

        # ä¿ç•™å…³é”®è¯ä½œä¸ºåå¤‡æœºåˆ¶ï¼ˆç”¨äºæœªæ˜ç¡®æ ‡æ³¨çš„æ¨¡å¼ï¼‰
        self.negative_keywords = {
            'ç©ºå¤´', 'ä¸‹è¡Œ', 'æ­»å‰', 'ä¸‹é™', 'è´Ÿå€¼', 'å¼±', 'ä½äº', 'çœ‹è·Œ',
            'ä¸‹è·Œ', 'å›è°ƒ', 'æ·±åº¦', 'çŸ­æœŸä¸‹é™', 'æ— ', 'æä½', 'ä¸¥é‡', 'è™šå¼±',
            'è€—å°½', 'é˜»åŠ›', 'å‹åˆ¶', 'ç ´ä½', 'è·Œç ´', 'å¤±å®ˆ', 'æ¶åŒ–', 'ç–²è½¯',
            'è¡°ç«­', 'åè½¬å‘ä¸‹', 'é¡¶éƒ¨', 'é«˜ä½', 'è¿‡çƒ­', 'æ³¡æ²«', 'é£é™©',
            'falling', 'bearish', 'below', 'negative', 'weak', 'down',
            'decline', 'drop', 'sell', 'short', 'resistance', 'break_down',
            'oversold', 'exhaustion', 'reversal_down', 'top', 'high', 'risk'
        }

    def is_negative_pattern(self, indicator_name: str, pattern_name: str, display_name: str = "") -> bool:
        """
        åˆ¤æ–­æ¨¡å¼æ˜¯å¦ä¸ºè´Ÿé¢æ¨¡å¼

        ä¼˜å…ˆçº§ï¼š
        1. ä»æ¨¡å¼æ³¨å†Œä¿¡æ¯ä¸­è·å–ææ€§
        2. å…³é”®è¯åŒ¹é…ä½œä¸ºåå¤‡æœºåˆ¶

        Args:
            indicator_name: æŒ‡æ ‡åç§°
            pattern_name: æ¨¡å¼åç§°
            display_name: æ˜¾ç¤ºåç§°

        Returns:
            bool: æ˜¯å¦ä¸ºè´Ÿé¢æ¨¡å¼
        """
        # 1. ä¼˜å…ˆä»æ¨¡å¼æ³¨å†Œä¿¡æ¯ä¸­è·å–ææ€§
        pattern_id = f"{indicator_name}_{pattern_name}"
        pattern_info = self.registry.get_pattern(pattern_id)

        if pattern_info and 'polarity' in pattern_info:
            polarity = pattern_info['polarity']
            if polarity == self.polarity_enum.NEGATIVE:
                return True
            elif polarity == self.polarity_enum.POSITIVE:
                return False
            # NEUTRAL ç»§ç»­ä½¿ç”¨å…³é”®è¯åˆ¤æ–­

        # 2. å…³é”®è¯åŒ¹é…ä½œä¸ºåå¤‡æœºåˆ¶
        text = f"{indicator_name} {pattern_name} {display_name}".lower()

        # ç‰¹æ®Šè§„åˆ™ï¼šåŒ…å«"æ— ...ä¿¡å·"çš„æ¨¡å¼
        if 'æ— ' in text and 'ä¿¡å·' in text:
            return True

        # æ£€æŸ¥è´Ÿé¢å…³é”®è¯
        for keyword in self.negative_keywords:
            if keyword.lower() in text:
                return True

        return False


class BuyPointBatchAnalyzer:
    """ä¹°ç‚¹æ‰¹é‡åˆ†æå™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–åˆ†æå™¨"""
        self.data_processor = PeriodDataProcessor()
        self.indicator_analyzer = AutoIndicatorAnalyzer()
        self.strategy_generator = StrategyGenerator()
        self.polarity_filter = PatternPolarityFilter()
        # P0çº§ä»»åŠ¡ï¼šæ·»åŠ éªŒè¯å™¨
        self.buypoint_validator = BuyPointValidator()
        self.data_quality_validator = DataQualityValidator()
        # P1çº§ä»»åŠ¡ï¼šæ·»åŠ ç­–ç•¥ä¼˜åŒ–å™¨å’Œç³»ç»Ÿç›‘æ§å™¨
        self.strategy_optimizer = StrategyOptimizer()
        self.system_monitor = SystemHealthMonitor()
        
    def load_buypoints_from_csv(self, csv_file: str) -> pd.DataFrame:
        """
        ä»CSVæ–‡ä»¶åŠ è½½ä¹°ç‚¹æ•°æ®
        
        Args:
            csv_file: CSVæ–‡ä»¶è·¯å¾„
            
        Returns:
            pd.DataFrame: ä¹°ç‚¹æ•°æ®
        """
        try:
            # è¯»å–CSVæ–‡ä»¶
            buypoints_df = pd.read_csv(csv_file)
            
            # éªŒè¯å¿…è¦çš„åˆ—
            required_columns = ['stock_code', 'buypoint_date']
            for col in required_columns:
                if col not in buypoints_df.columns:
                    raise ValueError(f"CSVæ–‡ä»¶ç¼ºå°‘å¿…è¦çš„åˆ—: {col}")
            
            # ç¡®ä¿æ—¥æœŸæ ¼å¼æ­£ç¡®
            try:
                # å°è¯•è½¬æ¢æ—¥æœŸæ ¼å¼
                buypoints_df['buypoint_date'] = pd.to_datetime(buypoints_df['buypoint_date'], format='%Y%m%d', errors='coerce')
                
                # æ£€æŸ¥æ˜¯å¦æœ‰æ— æ•ˆæ—¥æœŸï¼ˆNaTï¼‰
                invalid_dates = buypoints_df['buypoint_date'].isna()
                if invalid_dates.any():
                    logger.warning(f"å‘ç° {invalid_dates.sum()} æ¡æ— æ•ˆæ—¥æœŸè®°å½•ï¼Œå°†ä½¿ç”¨å½“å‰æ—¥æœŸæ›¿ä»£")
                    buypoints_df.loc[invalid_dates, 'buypoint_date'] = pd.Timestamp.now()
                    
                # å°†æ—¥æœŸæ ¼å¼åŒ–ä¸ºYYYYMMDDæ ¼å¼çš„å­—ç¬¦ä¸²
                buypoints_df['buypoint_date'] = buypoints_df['buypoint_date'].dt.strftime('%Y%m%d')
                
                # ç¡®ä¿æ²¡æœ‰"19700101"è¿™æ ·çš„é»˜è®¤æ—¥æœŸ
                default_date_mask = buypoints_df['buypoint_date'] == '19700101'
                if default_date_mask.any():
                    logger.warning(f"å‘ç° {default_date_mask.sum()} æ¡é»˜è®¤æ—¥æœŸ(19700101)è®°å½•ï¼Œå°†ä½¿ç”¨å½“å‰æ—¥æœŸæ›¿ä»£")
                    today = datetime.now().strftime('%Y%m%d')
                    buypoints_df.loc[default_date_mask, 'buypoint_date'] = today
                
            except Exception as e:
                logger.error(f"æ—¥æœŸæ ¼å¼è½¬æ¢é”™è¯¯: {e}")
                # å¦‚æœè½¬æ¢å¤±è´¥ï¼Œä½¿ç”¨å½“å‰æ—¥æœŸ
                today = datetime.now().strftime('%Y%m%d')
                buypoints_df['buypoint_date'] = today
                logger.warning(f"ä½¿ç”¨å½“å‰æ—¥æœŸ {today} ä½œä¸ºæ‰€æœ‰ä¹°ç‚¹çš„æ—¥æœŸ")
            
            # å¦‚æœcodeä¸å¤Ÿ6ä½ï¼Œè¡¥é½6ä½ï¼Œå‰é¢è¡¥ 0ï¼Œç›´åˆ°6ä½
            buypoints_df['stock_code'] = buypoints_df['stock_code'].astype(str).str.zfill(6)
            logger.info(f"å·²åŠ è½½ {len(buypoints_df)} ä¸ªä¹°ç‚¹")
            return buypoints_df
            
        except Exception as e:
            logger.error(f"åŠ è½½ä¹°ç‚¹CSVæ–‡ä»¶æ—¶å‡ºé”™: {e}")
            return pd.DataFrame()
    
    def analyze_single_buypoint(self, 
                             stock_code: str, 
                             buypoint_date: str) -> Dict[str, Any]:
        """
        åˆ†æå•ä¸ªä¹°ç‚¹
        
        Args:
            stock_code: è‚¡ç¥¨ä»£ç 
            buypoint_date: ä¹°ç‚¹æ—¥æœŸ
            
        Returns:
            Dict[str, Any]: åˆ†æç»“æœ
        """
        try:
            logger.info(f"å¼€å§‹åˆ†æä¹°ç‚¹: {stock_code} {buypoint_date}")
            
            # è·å–å¤šå‘¨æœŸæ•°æ®
            stock_data = self.data_processor.get_multi_period_data(
                stock_code=stock_code,
                end_date=buypoint_date
            )

            # å¦‚æœæ²¡æœ‰è·å–åˆ°æ•°æ®ï¼Œè¿”å›ç©ºç»“æœ
            if not stock_data:
                logger.warning(f"æœªèƒ½è·å– {stock_code} çš„æ•°æ®")
                return {}

            # P0çº§ä»»åŠ¡ï¼šæ·»åŠ æ•°æ®è´¨é‡éªŒè¯
            data_quality_result = self.data_quality_validator.validate_multi_period_data(
                stock_code=stock_code,
                date=buypoint_date
            )

            # æ£€æŸ¥æ•°æ®è´¨é‡
            if data_quality_result['overall_quality'] in ['poor', 'error']:
                logger.warning(f"è‚¡ç¥¨ {stock_code} æ•°æ®è´¨é‡è¾ƒå·®: {data_quality_result['overall_quality']}")
                # è®°å½•è´¨é‡é—®é¢˜ä½†ç»§ç»­åˆ†æ
                quality_issues = data_quality_result.get('issues', [])
                if quality_issues:
                    logger.warning(f"æ•°æ®è´¨é‡é—®é¢˜: {quality_issues}")
            elif data_quality_result['overall_quality'] == 'excellent':
                logger.debug(f"è‚¡ç¥¨ {stock_code} æ•°æ®è´¨é‡ä¼˜ç§€")
                
            # æ£€æŸ¥æ•°æ®æ˜¯å¦è¶³å¤Ÿè®¡ç®—æŒ‡æ ‡
            min_required_length = 30  # è®¾ç½®æœ€å°æ‰€éœ€æ•°æ®é•¿åº¦
            required_columns = ['open', 'high', 'low', 'close', 'volume']

            # å¤„ç†æ¯ä¸ªå‘¨æœŸçš„æ•°æ®
            for period, df in stock_data.items():
                if len(df) < min_required_length:
                    logger.warning(f"å‘¨æœŸ {period} çš„æ•°æ®é•¿åº¦ ({len(df)}) ä¸è¶³ä»¥è®¡ç®—æ‰€æœ‰æŒ‡æ ‡ï¼Œå¯èƒ½å½±å“åˆ†æç»“æœå‡†ç¡®æ€§")

                # ç¡®ä¿æ•°æ®åŒ…å«æ‰€æœ‰å¿…è¦çš„åˆ—ï¼Œä½†ä¿ç•™æ‰€æœ‰ç°æœ‰åˆ—
                stock_data[period] = self._prepare_data_for_analysis(df, required_columns)
            
            # å®šä½ç›®æ ‡è¡Œ - ä¸€èˆ¬æ˜¯æœ€æ–°çš„æ•°æ®ç‚¹
            target_rows = {}
            for period, df in stock_data.items():
                if df.empty:
                    logger.warning(f"å‘¨æœŸ {period} çš„æ•°æ®ä¸ºç©ºï¼Œè·³è¿‡åˆ†æ")
                    continue
                
                target_rows[period] = len(df) - 1  # é»˜è®¤ä½¿ç”¨æœ€åä¸€è¡Œ
            
            # åˆ†ææŒ‡æ ‡
            indicator_results = self.indicator_analyzer.analyze_all_indicators(
                stock_data,
                target_rows
            )
            
            # å¦‚æœæ²¡æœ‰è·å–åˆ°ä»»ä½•æŒ‡æ ‡ç»“æœï¼Œè¿”å›ç©ºç»“æœ
            if not indicator_results:
                logger.warning(f"æœªèƒ½è·å– {stock_code} çš„æŒ‡æ ‡åˆ†æç»“æœ")
                return {}
            
            # ç»„ç»‡åˆ†æç»“æœ
            result = {
                'stock_code': stock_code,
                'buypoint_date': buypoint_date,
                'indicator_results': indicator_results,
                'data_quality': data_quality_result  # P0çº§ä»»åŠ¡ï¼šåŒ…å«æ•°æ®è´¨é‡ä¿¡æ¯
            }
            
            return result
            
        except Exception as e:
            logger.error(f"åˆ†æä¹°ç‚¹ {stock_code} {buypoint_date} æ—¶å‡ºé”™: {e}")
            return {}
    
    def _prepare_data_for_analysis(self, df: pd.DataFrame, required_columns: List[str]) -> pd.DataFrame:
        """
        å‡†å¤‡æ•°æ®ä»¥è¿›è¡Œåˆ†æï¼Œç¡®ä¿æ•°æ®åŒ…å«æ‰€æœ‰å¿…è¦çš„åˆ—
        
        Args:
            df: åŸå§‹æ•°æ®
            required_columns: å¿…è¦çš„åˆ—ååˆ—è¡¨
        
        Returns:
            pd.DataFrame: å‡†å¤‡å¥½çš„æ•°æ®
        """
        try:
            if df is None or df.empty:
                logger.warning("è¾“å…¥æ•°æ®ä¸ºç©ºï¼Œæ— æ³•å‡†å¤‡æ•°æ®")
                # åˆ›å»ºç©ºçš„DataFrameä½†åŒ…å«æ‰€æœ‰éœ€è¦çš„åˆ—
                return pd.DataFrame(columns=required_columns)
            
            # æ£€æŸ¥å¿…è¦çš„åˆ—æ˜¯å¦å­˜åœ¨
            missing_cols = [col for col in required_columns if col not in df.columns]
            
            result = df.copy()

            if missing_cols:
                logger.warning(f"æ•°æ® {list(df.columns)} ç¼ºå°‘æ‰€éœ€çš„åˆ—: {missing_cols}")
                
                # æ£€æŸ¥æ ¸å¿ƒä»·æ ¼åˆ—æ˜¯å¦å®Œå…¨ç¼ºå¤±
                price_cols = ['open', 'high', 'low', 'close']
                if all(col not in result.columns for col in price_cols):
                    logger.error("æ ¸å¿ƒä»·æ ¼æ•°æ® (open, high, low, close) å®Œå…¨ç¼ºå¤±ï¼Œæ— æ³•ç»§ç»­åˆ†æ")
                    return pd.DataFrame(columns=required_columns)

                # ä¸ºç¼ºå¤±çš„åˆ—åˆ›å»ºé»˜è®¤å€¼
                for col in missing_cols:
                    if col in price_cols:
                        # å¦‚æœæœ‰å…¶ä»–ä»·æ ¼åˆ—ï¼Œä½¿ç”¨å®ƒä»¬å¡«å……
                        existing_price_col = next((p for p in price_cols if p in result.columns), None)
                        if existing_price_col:
                            result[col] = result[existing_price_col]
                            logger.info(f"ä½¿ç”¨ {existing_price_col} åˆ—å¡«å……ç¼ºå¤±çš„ {col} åˆ—")
                        else:
                            # å¦‚æœæ‰€æœ‰ä»·æ ¼åˆ—éƒ½ç¼ºå¤±ï¼Œä½¿ç”¨é»˜è®¤å€¼
                            result[col] = 10.0  # ä½¿ç”¨åˆç†çš„é»˜è®¤ä»·æ ¼
                            logger.warning(f"æ‰€æœ‰ä»·æ ¼åˆ—éƒ½ç¼ºå¤±ï¼Œä¸º {col} åˆ—è®¾ç½®é»˜è®¤å€¼ 10.0")
                    elif col == 'volume':
                        result[col] = 1000  # ä½¿ç”¨åˆç†çš„é»˜è®¤æˆäº¤é‡
                        logger.info(f"ä¸ºç¼ºå¤±çš„ {col} åˆ—è®¾ç½®é»˜è®¤å€¼ 1000")
                    else:
                        result[col] = 0.0
                        logger.info(f"ä¸ºç¼ºå¤±çš„ {col} åˆ—è®¾ç½®é»˜è®¤å€¼ 0.0")
            
            # å¡«å……å¯èƒ½å­˜åœ¨çš„NaNå€¼
            result = result.ffill().bfill()
            
            # ç¡®ä¿æ‰€æœ‰åˆ—éƒ½å­˜åœ¨
            final_missing = [col for col in required_columns if col not in result.columns]
            if final_missing:
                for col in final_missing:
                    result[col] = 0
            
            # è¿”å›åŒ…å«æ‰€æœ‰åˆ—çš„DataFrameï¼Œä¸åªæ˜¯å¿…éœ€åˆ—ï¼Œè¿™æ ·å¯ä»¥ä¿ç•™è¡ç”Ÿåˆ—å¦‚MA5ã€kã€dã€jç­‰
            return result

        except Exception as e:
            logger.error(f"å‡†å¤‡æ•°æ®æ—¶å‡ºé”™: {e}")
            # è¿”å›åŒ…å«æ‰€éœ€åˆ—çš„ç©ºDataFrame
            return pd.DataFrame(columns=required_columns)
    
    def analyze_batch_buypoints(self, 
                             buypoints_df: pd.DataFrame) -> List[Dict[str, Any]]:
        """
        æ‰¹é‡åˆ†æä¹°ç‚¹
        
        Args:
            buypoints_df: ä¹°ç‚¹æ•°æ®DataFrame
            
        Returns:
            List[Dict[str, Any]]: åˆ†æç»“æœåˆ—è¡¨
        """
        results = []
        total_count = len(buypoints_df)

        logger.info(f"å¼€å§‹æ‰¹é‡åˆ†æ {total_count} ä¸ªä¹°ç‚¹")

        # éå†æ‰€æœ‰ä¹°ç‚¹
        for idx, row in buypoints_df.iterrows():
            stock_code = row['stock_code']
            buypoint_date = row['buypoint_date']

            # P2çº§ä»»åŠ¡ï¼šæ”¹è¿›è¿›åº¦æ˜¾ç¤º
            progress_percent = (idx + 1) / total_count * 100
            progress_bar = "â–ˆ" * int(progress_percent // 5) + "â–‘" * (20 - int(progress_percent // 5))
            logger.info(f"ğŸ“Š åˆ†æè¿›åº¦: [{progress_bar}] {progress_percent:.1f}% ({idx + 1}/{total_count}) - {stock_code}")

            try:
                # åˆ†æå•ä¸ªä¹°ç‚¹
                buypoint_result = self.analyze_single_buypoint(
                    stock_code=stock_code,
                    buypoint_date=buypoint_date
                )

                # å¦‚æœæœ‰ç»“æœï¼Œæ·»åŠ åˆ°åˆ—è¡¨
                if buypoint_result:
                    results.append(buypoint_result)

            except Exception as e:
                logger.error(f"âŒ åˆ†æä¹°ç‚¹ {stock_code} ({buypoint_date}) æ—¶å‡ºé”™: {e}")
                continue

        logger.info(f"âœ… æ‰¹é‡åˆ†æå®Œæˆï¼ŒæˆåŠŸåˆ†æ {len(results)}/{total_count} ä¸ªä¹°ç‚¹")
        return results
    
    def extract_common_indicators(self,
                              buypoint_results: List[Dict[str, Any]],
                              min_hit_ratio: float = 0.6,
                              filter_negative_patterns: bool = True) -> Dict[str, List[Dict[str, Any]]]:
        """
        æå–å…±æ€§æŒ‡æ ‡

        Args:
            buypoint_results: ä¹°ç‚¹åˆ†æç»“æœåˆ—è¡¨
            min_hit_ratio: æœ€å°å‘½ä¸­æ¯”ä¾‹ï¼Œé»˜è®¤0.6ï¼ˆ60%ï¼‰
            filter_negative_patterns: æ˜¯å¦è¿‡æ»¤è´Ÿé¢æ¨¡å¼ï¼Œé»˜è®¤True

        Returns:
            Dict[str, List[Dict[str, Any]]]: æŒ‰å‘¨æœŸåˆ†ç»„çš„å…±æ€§æŒ‡æ ‡åˆ—è¡¨
        """
        try:
            # å¦‚æœç»“æœä¸ºç©ºï¼Œè¿”å›ç©ºå­—å…¸
            if not buypoint_results:
                return {}

            # æŒ‰å‘¨æœŸåˆ†ç»„çš„æŒ‡æ ‡ç»Ÿè®¡
            period_indicators = defaultdict(lambda: defaultdict(list))

            # å®šä¹‰æœ‰æ•ˆçš„æ—¶é—´å‘¨æœŸåˆ—è¡¨ï¼Œç”¨äºéªŒè¯æ•°æ®ä¸€è‡´æ€§
            valid_periods = {'15min', '30min', '60min', 'daily', 'weekly', 'monthly'}
            
            # éå†æ‰€æœ‰ä¹°ç‚¹ç»“æœ
            for result in buypoint_results:
                # éå†æ¯ä¸ªå‘¨æœŸ
                for period, indicators in result.get('indicator_results', {}).items():
                    # éªŒè¯æ—¶é—´å‘¨æœŸçš„æœ‰æ•ˆæ€§ï¼Œç¡®ä¿æ•°æ®ä¸€è‡´æ€§
                    if period not in valid_periods:
                        logger.warning(f"å‘ç°æ— æ•ˆçš„æ—¶é—´å‘¨æœŸ: {period}ï¼Œè·³è¿‡è¯¥å‘¨æœŸæ•°æ®")
                        continue

                    # éå†è¯¥å‘¨æœŸä¸‹çš„æ‰€æœ‰æŒ‡æ ‡
                    for indicator in indicators:
                        # æ£€æŸ¥æŒ‡æ ‡ç»“æ„ï¼Œç¡®ä¿å¿…è¦çš„å­—æ®µå­˜åœ¨
                        if 'indicator_name' not in indicator or 'pattern_id' not in indicator:
                            continue

                        # éªŒè¯æŒ‡æ ‡æ•°æ®æ˜¯å¦çœŸçš„å±äºå½“å‰æ—¶é—´å‘¨æœŸ
                        indicator_name = indicator['indicator_name']
                        original_pattern_id = indicator['pattern_id']

                        # æ£€æŸ¥æŒ‡æ ‡åç§°æ˜¯å¦åŒ…å«ä¸åŒ¹é…çš„æ—¶é—´å‘¨æœŸä¿¡æ¯
                        if self._validate_period_consistency(indicator_name, original_pattern_id, period):
                            logger.debug(f"æ—¶é—´å‘¨æœŸä¸ä¸€è‡´ï¼Œè·³è¿‡: {indicator_name}_{original_pattern_id} åœ¨ {period} å‘¨æœŸä¸­")
                            continue

                        # æ ‡å‡†åŒ–pattern_idï¼Œé¿å…æ¨¡ç³Šæè¿°
                        standardized_pattern_id = self._standardize_pattern_description(
                            original_pattern_id,
                            indicator_name,
                            original_pattern_id
                        )

                        # æ„å»ºæŒ‡æ ‡æ ‡è¯†ï¼ˆæŒ‡æ ‡å_æ ‡å‡†åŒ–å½¢æ€IDï¼‰
                        indicator_id = f"{indicator_name}_{standardized_pattern_id}"

                        # å¦‚æœå¯ç”¨è´Ÿé¢æ¨¡å¼è¿‡æ»¤ï¼Œæ£€æŸ¥æ˜¯å¦ä¸ºè´Ÿé¢æ¨¡å¼
                        if filter_negative_patterns:
                            pattern_name = indicator.get('pattern_name', indicator.get('pattern_id', ''))
                            display_name = indicator.get('pattern_name', '')

                            if self.polarity_filter.is_negative_pattern(indicator_name, pattern_name, display_name):
                                logger.debug(f"è¿‡æ»¤è´Ÿé¢æ¨¡å¼: {indicator_name} - {pattern_name}")
                                continue

                        # ä¿®å¤è¯„åˆ†æ•°æ®å¼‚å¸¸ï¼šä¼˜å…ˆä½¿ç”¨score_impactï¼Œå…¶æ¬¡ä½¿ç”¨score
                        score_value = indicator.get('score_impact', indicator.get('score', 0))
                        if score_value == 0:
                            # å¦‚æœè¯„åˆ†ä¸º0ï¼Œå°è¯•ä»å…¶ä»–å­—æ®µè·å–
                            score_value = indicator.get('strength_score', indicator.get('pattern_score', 0))

                        # ä¼˜åŒ–å½¢æ€æè¿°ï¼Œä½¿ç”¨æ ‡å‡†æŠ€æœ¯åˆ†ææœ¯è¯­
                        display_name = self._standardize_pattern_description(
                            indicator.get('pattern_name', original_pattern_id),
                            indicator_name,
                            original_pattern_id
                        )

                        # æ·»åŠ åˆ°å¯¹åº”å‘¨æœŸçš„æŒ‡æ ‡åˆ—è¡¨
                        period_indicators[period][indicator_id].append({
                            'stock_code': result['stock_code'],
                            'buypoint_date': result['buypoint_date'],
                            'score': score_value,
                            'details': {
                                'display_name': display_name,
                                'pattern_id': standardized_pattern_id,  # ä½¿ç”¨æ ‡å‡†åŒ–åçš„pattern_id
                                'description': indicator.get('description', ''),
                                'pattern_type': indicator.get('pattern_type', ''),
                                'original_name': indicator.get('pattern_name', original_pattern_id),  # ä¿ç•™åŸå§‹åç§°ç”¨äºè°ƒè¯•
                                'original_pattern_id': original_pattern_id  # ä¿ç•™åŸå§‹pattern_idç”¨äºè°ƒè¯•
                            }
                        })
            
            # è®¡ç®—æ¯ä¸ªå‘¨æœŸä¸‹å„æŒ‡æ ‡çš„å‘½ä¸­ç‡å’Œå¹³å‡å¾—åˆ†
            common_indicators = {}
            total_buypoints = len(buypoint_results)

            logger.info(f"å¼€å§‹æå–å…±æ€§æŒ‡æ ‡ï¼Œæ€»ä¹°ç‚¹æ•°é‡: {total_buypoints}, æœ€å°å‘½ä¸­ç‡é˜ˆå€¼: {min_hit_ratio:.1%}, "
                       f"è´Ÿé¢æ¨¡å¼è¿‡æ»¤: {'å¯ç”¨' if filter_negative_patterns else 'ç¦ç”¨'}")

            for period, indicators in period_indicators.items():
                period_common = []

                for indicator_id, hits in indicators.items():
                    # ä¿®å¤å‘½ä¸­ç‡è®¡ç®—ï¼šè®¡ç®—åŒ…å«è¯¥æŒ‡æ ‡çš„å”¯ä¸€è‚¡ç¥¨æ•°é‡
                    # æ¯ä¸ªè‚¡ç¥¨åœ¨æ¯ä¸ªæ¨¡å¼ä¸­åªè®¡ç®—ä¸€æ¬¡ï¼Œæ— è®ºè¯¥æ¨¡å¼å‡ºç°å¤šå°‘æ¬¡
                    unique_stocks = set()
                    for hit in hits:
                        # ä½¿ç”¨è‚¡ç¥¨ä»£ç å’Œä¹°ç‚¹æ—¥æœŸç»„åˆä½œä¸ºå”¯ä¸€æ ‡è¯†
                        stock_key = f"{hit['stock_code']}_{hit['buypoint_date']}"
                        unique_stocks.add(stock_key)

                    # æ­£ç¡®çš„å‘½ä¸­ç‡è®¡ç®—ï¼šå”¯ä¸€è‚¡ç¥¨æ•°é‡ / æ€»ä¹°ç‚¹æ•°é‡
                    hit_ratio = len(unique_stocks) / total_buypoints
                    unique_stock_count = len(unique_stocks)

                    # éªŒè¯å‘½ä¸­ç‡åœ¨åˆç†èŒƒå›´å†…
                    assert 0.0 <= hit_ratio <= 1.0, f"å‘½ä¸­ç‡è®¡ç®—é”™è¯¯: {hit_ratio:.3f} for {indicator_id}"

                    # æ·»åŠ è¯¦ç»†æ—¥å¿—ç”¨äºè°ƒè¯•
                    logger.debug(f"æŒ‡æ ‡ {indicator_id}: æ€»å‡ºç°æ¬¡æ•°={len(hits)}, å”¯ä¸€è‚¡ç¥¨æ•°={unique_stock_count}, "
                               f"æ€»ä¹°ç‚¹æ•°={total_buypoints}, å‘½ä¸­ç‡={hit_ratio:.1%}")

                    # å¦‚æœå‘½ä¸­ç‡è¾¾åˆ°é˜ˆå€¼ï¼Œè®¤ä¸ºæ˜¯å…±æ€§æŒ‡æ ‡
                    if hit_ratio >= min_hit_ratio:
                        # è®¡ç®—å¹³å‡å¾—åˆ†
                        avg_score = sum(hit.get('score', 0) for hit in hits) / len(hits)

                        # æ‹†åˆ†æŒ‡æ ‡ID
                        parts = indicator_id.split('_', 1)

                        if len(parts) >= 2:
                            indicator_name = parts[0]
                            pattern_name = parts[1]

                            # ä½¿ç”¨å®é™…çš„display_nameï¼ˆå¦‚æœæœ‰ï¼‰
                            display_name = hits[0].get('details', {}).get('display_name', pattern_name)

                            period_common.append({
                                'type': 'indicator',
                                'name': indicator_name,
                                'pattern': display_name,  # ä½¿ç”¨æ ‡å‡†åŒ–åçš„display_nameä½œä¸ºpatternå­—æ®µ
                                'display_name': display_name,
                                'original_pattern': pattern_name,  # ä¿ç•™åŸå§‹pattern_nameç”¨äºè°ƒè¯•
                                'hit_ratio': hit_ratio,
                                'hit_count': unique_stock_count,  # ä½¿ç”¨å”¯ä¸€è‚¡ç¥¨æ•°é‡ï¼Œä¸æ˜¯æ€»å‡ºç°æ¬¡æ•°
                                'avg_score': avg_score,
                                'hits': hits,
                                'unique_stocks': list(unique_stocks)  # æ·»åŠ è°ƒè¯•ä¿¡æ¯
                            })
                        else:
                            # å¦‚æœæ— æ³•æ­£ç¡®è§£æï¼Œä½¿ç”¨å®Œæ•´çš„indicator_idä½œä¸ºåç§°
                            period_common.append({
                                'type': 'indicator',
                                'name': indicator_id,
                                'pattern': '',
                                'display_name': indicator_id,
                                'hit_ratio': hit_ratio,
                                'hit_count': unique_stock_count,  # ä½¿ç”¨å”¯ä¸€è‚¡ç¥¨æ•°é‡ï¼Œä¸æ˜¯æ€»å‡ºç°æ¬¡æ•°
                                'avg_score': avg_score,
                                'hits': hits,
                                'unique_stocks': list(unique_stocks)  # æ·»åŠ è°ƒè¯•ä¿¡æ¯
                            })
                
                # æŒ‰å¹³å‡å¾—åˆ†æ’åº
                period_common.sort(key=lambda x: x['avg_score'], reverse=True)
                
                # å­˜å‚¨åˆ°ç»“æœå­—å…¸
                if period_common:
                    common_indicators[period] = period_common
                    logger.info(f"{period}å‘¨æœŸæ‰¾åˆ° {len(period_common)} ä¸ªå…±æ€§æŒ‡æ ‡")
                else:
                    logger.warning(f"{period}å‘¨æœŸæœªæ‰¾åˆ°æ»¡è¶³é˜ˆå€¼çš„å…±æ€§æŒ‡æ ‡")
            
            return common_indicators
            
        except Exception as e:
            logger.error(f"æå–å…±æ€§æŒ‡æ ‡æ—¶å‡ºé”™: {e}")
            return {}

    def _validate_period_consistency(self, indicator_name: str, pattern_id: str, expected_period: str) -> bool:
        """
        éªŒè¯æŒ‡æ ‡æ•°æ®æ˜¯å¦ä¸æœŸæœ›çš„æ—¶é—´å‘¨æœŸä¸€è‡´

        Args:
            indicator_name: æŒ‡æ ‡åç§°
            pattern_id: å½¢æ€ID
            expected_period: æœŸæœ›çš„æ—¶é—´å‘¨æœŸ

        Returns:
            bool: Trueè¡¨ç¤ºä¸ä¸€è‡´ï¼ˆåº”è¯¥è·³è¿‡ï¼‰ï¼ŒFalseè¡¨ç¤ºä¸€è‡´
        """
        # æ£€æŸ¥æŒ‡æ ‡åç§°æˆ–å½¢æ€IDä¸­æ˜¯å¦åŒ…å«å…¶ä»–æ—¶é—´å‘¨æœŸçš„æ ‡è¯†
        other_periods = {'15min', '30min', '60min', 'daily', 'weekly', 'monthly'} - {expected_period}

        # æ—¶é—´å‘¨æœŸå…³é”®è¯æ˜ å°„
        period_keywords = {
            'daily': ['æ—¥çº¿', 'æ—¥K', 'daily', 'day'],
            'weekly': ['å‘¨çº¿', 'å‘¨K', 'weekly', 'week'],
            'monthly': ['æœˆçº¿', 'æœˆK', 'monthly', 'month'],
            '15min': ['15åˆ†é’Ÿ', '15min'],
            '30min': ['30åˆ†é’Ÿ', '30min'],
            '60min': ['60åˆ†é’Ÿ', '60min', '1å°æ—¶', '1hour']
        }

        # æ£€æŸ¥æ˜¯å¦åŒ…å«å…¶ä»–å‘¨æœŸçš„å…³é”®è¯
        text_to_check = f"{indicator_name} {pattern_id}".lower()

        for period in other_periods:
            keywords = period_keywords.get(period, [])
            for keyword in keywords:
                if keyword.lower() in text_to_check:
                    return True  # å‘ç°ä¸ä¸€è‡´ï¼Œåº”è¯¥è·³è¿‡

        return False  # ä¸€è‡´ï¼Œä¸éœ€è¦è·³è¿‡

    def _standardize_pattern_description(self, original_name: str, indicator_name: str, pattern_id: str) -> str:
        """
        æ ‡å‡†åŒ–å½¢æ€æè¿°ï¼Œä½¿ç”¨æ›´ä¸“ä¸šçš„æœ¯è¯­
        
        Args:
            original_name: åŸå§‹å½¢æ€åç§°
            indicator_name: æŒ‡æ ‡åç§°
            pattern_id: å½¢æ€ID
            
        Returns:
            str: æ ‡å‡†åŒ–åçš„å½¢æ€æè¿°
        """
        # å¦‚æœåŸå§‹åç§°ä¸ºç©ºï¼Œåˆ™ä½¿ç”¨å½¢æ€ID
        if not original_name or original_name == '-':
            return f"{indicator_name}æŒ‡æ ‡{pattern_id}å½¢æ€"
            
        # å¦‚æœåŸå§‹åç§°åŒ…å«"åŸºäº"ï¼Œåˆ™å°è¯•æå–æ›´å…·ä½“çš„å½¢æ€æè¿°
        if "åŸºäº" in original_name and "åˆ†æ:" in original_name:
            parts = original_name.split("åˆ†æ:")
            if len(parts) > 1:
                specific_pattern = parts[1].strip()
                if specific_pattern:
                    return f"{indicator_name}æŒ‡æ ‡{specific_pattern}å½¢æ€"
        
        # å¦‚æœæ²¡æœ‰ç‰¹æ®Šå¤„ç†ï¼Œåˆ™ç›´æ¥è¿”å›åŸå§‹åç§°
        return original_name
        
    def get_precise_pattern_info(self, indicator_name: str, pattern: str, description: str) -> Dict[str, str]:
        """
        è·å–ç²¾ç¡®çš„å½¢æ€ä¿¡æ¯ï¼Œä¼˜å…ˆä»PatternRegistryæŸ¥æ‰¾ï¼Œç„¶åå›é€€åˆ°æ˜ å°„å­—å…¸

        Args:
            indicator_name: æŒ‡æ ‡åç§°
            pattern: å½¢æ€åç§°
            description: å½¢æ€æè¿°

        Returns:
            Dict[str, str]: åŒ…å«å½¢æ€åç§°å’Œæè¿°çš„å­—å…¸
        """
        # 1. ä¼˜å…ˆä»PatternRegistryæŸ¥æ‰¾
        registry = PatternRegistry()

        # 1.1 å°è¯•ç›´æ¥é€šè¿‡æŒ‡æ ‡åç§°å’Œå½¢æ€IDæŸ¥æ‰¾
        pattern_id = f"{indicator_name}_{pattern}".upper()
        pattern_info = registry.get_pattern(pattern_id)
        if pattern_info:
            return {
                'name': pattern_info.get('display_name', pattern),
                'description': pattern_info.get('description', description or f"{indicator_name}æŒ‡æ ‡çš„{pattern}æŠ€æœ¯åˆ†æ")
            }

        # 1.2 å°è¯•é€šè¿‡å½¢æ€IDç›´æ¥æŸ¥æ‰¾ï¼ˆå¯èƒ½å·²ç»åŒ…å«æŒ‡æ ‡å‰ç¼€ï¼‰
        pattern_info = registry.get_pattern(pattern.upper())
        if pattern_info:
            return {
                'name': pattern_info.get('display_name', pattern),
                'description': pattern_info.get('description', description or f"{indicator_name}æŒ‡æ ‡çš„{pattern}æŠ€æœ¯åˆ†æ")
            }

        # 1.3 å°è¯•é€šè¿‡æŒ‡æ ‡åç§°è·å–æ‰€æœ‰ç›¸å…³å½¢æ€ï¼Œç„¶åæ¨¡ç³ŠåŒ¹é…
        indicator_patterns = registry.get_pattern_infos_by_indicator(indicator_name)
        if indicator_patterns:
            for pattern_info in indicator_patterns:
                display_name = pattern_info.get('display_name', '')
                pattern_desc = pattern_info.get('description', '')

                # æ£€æŸ¥æ˜¯å¦åŒ¹é…
                if (pattern == display_name or
                    pattern in display_name or
                    display_name in pattern or
                    pattern.replace('_', ' ').lower() in display_name.lower() or
                    display_name.lower() in pattern.replace('_', ' ').lower()):
                    return {
                        'name': display_name,
                        'description': pattern_desc or description or f"{indicator_name}æŒ‡æ ‡çš„{pattern}æŠ€æœ¯åˆ†æ"
                    }

        # 2. ç‰¹æ®Šå¤„ç†ZXMç³»åˆ—æŒ‡æ ‡
        if indicator_name.startswith('ZXM'):
            # ZXMç³»åˆ—æŒ‡æ ‡å·²ç»åœ¨æŒ‡æ ‡ç±»ä¸­ç›´æ¥æ³¨å†Œå½¢æ€ï¼Œä½¿ç”¨PatternRegistry
            pass

        # 3. å¤„ç†å¸¸è§çš„è‹±æ–‡å½¢æ€å‘½åæ¨¡å¼ï¼Œè½¬æ¢ä¸ºä¸­æ–‡
        # 3.1 å¤„ç†"Xxx Yyy Zzz"æ ¼å¼çš„å½¢æ€åç§°
        if ' ' in pattern and pattern[0].isupper() and '_' not in pattern and not pattern.isupper():
            # å¦‚æœæ˜¯è‹±æ–‡å•è¯ç»„åˆçš„å½¢æ€åç§°ï¼Œå°è¯•è½¬æ¢ä¸ºæ›´å‹å¥½çš„ä¸­æ–‡è¡¨è¿°
            if pattern.startswith("Above"):
                chinese_pattern = f"ä½äº{pattern.replace('Above', '').strip()}ä¸Šæ–¹"
                return {'name': chinese_pattern, 'description': f"{indicator_name}æŒ‡æ ‡{chinese_pattern}"}
            elif pattern.startswith("Below"):
                chinese_pattern = f"ä½äº{pattern.replace('Below', '').strip()}ä¸‹æ–¹"
                return {'name': chinese_pattern, 'description': f"{indicator_name}æŒ‡æ ‡{chinese_pattern}"}
            elif pattern.startswith("Cross"):
                chinese_pattern = f"{pattern.replace('Cross', '').strip()}äº¤å‰"
                return {'name': chinese_pattern, 'description': f"{indicator_name}æŒ‡æ ‡å½¢æˆ{chinese_pattern}"}
            elif "Bullish" in pattern:
                chinese_pattern = f"çœ‹æ¶¨{pattern.replace('Bullish', '').strip()}"
                return {'name': chinese_pattern, 'description': f"{indicator_name}æŒ‡æ ‡æ˜¾ç¤º{chinese_pattern}å½¢æ€"}
            elif "Bearish" in pattern:
                chinese_pattern = f"çœ‹è·Œ{pattern.replace('Bearish', '').strip()}"
                return {'name': chinese_pattern, 'description': f"{indicator_name}æŒ‡æ ‡æ˜¾ç¤º{chinese_pattern}å½¢æ€"}
            elif "Rising" in pattern:
                chinese_pattern = f"{pattern.replace('Rising', '').strip()}ä¸Šå‡"
                return {'name': chinese_pattern, 'description': f"{indicator_name}æŒ‡æ ‡{chinese_pattern}"}
            elif "Falling" in pattern:
                chinese_pattern = f"{pattern.replace('Falling', '').strip()}ä¸‹é™"
                return {'name': chinese_pattern, 'description': f"{indicator_name}æŒ‡æ ‡{chinese_pattern}"}
            elif "Uptrend" in pattern:
                chinese_pattern = f"ä¸Šå‡è¶‹åŠ¿"
                return {'name': chinese_pattern, 'description': f"{indicator_name}æŒ‡æ ‡æ˜¾ç¤º{chinese_pattern}"}
            elif "Downtrend" in pattern:
                chinese_pattern = f"ä¸‹é™è¶‹åŠ¿"
                return {'name': chinese_pattern, 'description': f"{indicator_name}æŒ‡æ ‡æ˜¾ç¤º{chinese_pattern}"}
        
        # 3.2 å¤„ç†"XXX_YYY_ZZZ"æ ¼å¼çš„å½¢æ€ID
        if '_' in pattern and pattern.isupper():
            # å°†ä¸‹åˆ’çº¿åˆ†éš”çš„å¤§å†™å•è¯è½¬æ¢ä¸ºç©ºæ ¼åˆ†éš”çš„é¦–å­—æ¯å¤§å†™å•è¯
            words = pattern.split('_')
            readable_name = ' '.join(word.title() for word in words)
            
            # å°è¯•å°†å¸¸è§çš„æŠ€æœ¯æœ¯è¯­ç¿»è¯‘ä¸ºä¸­æ–‡
            translations = {
                'BULLISH': 'çœ‹æ¶¨',
                'BEARISH': 'çœ‹è·Œ',
                'CROSS': 'äº¤å‰',
                'GOLDEN': 'é‡‘å‰',
                'DEATH': 'æ­»å‰',
                'ABOVE': 'ä¸Šæ–¹',
                'BELOW': 'ä¸‹æ–¹',
                'RISING': 'ä¸Šå‡',
                'FALLING': 'ä¸‹é™',
                'UPTREND': 'ä¸Šå‡è¶‹åŠ¿',
                'DOWNTREND': 'ä¸‹é™è¶‹åŠ¿',
                'OVERBOUGHT': 'è¶…ä¹°',
                'OVERSOLD': 'è¶…å–',
                'DIVERGENCE': 'èƒŒç¦»',
                'CONVERGENCE': 'æ”¶æ•›',
                'SUPPORT': 'æ”¯æ’‘',
                'RESISTANCE': 'é˜»åŠ›',
                'BREAKOUT': 'çªç ´',
                'REVERSAL': 'åè½¬',
                'STRONG': 'å¼ºåŠ¿',
                'WEAK': 'å¼±åŠ¿',
                'SIGNAL': 'ä¿¡å·',
                'PATTERN': 'å½¢æ€',
                'CONSOLIDATION': 'ç›˜æ•´',
                'VOLATILITY': 'æ³¢åŠ¨æ€§',
                'MOMENTUM': 'åŠ¨é‡',
                'TREND': 'è¶‹åŠ¿'
            }
            
            # å°è¯•ç¿»è¯‘å½¢æ€åç§°
            chinese_words = []
            for word in words:
                if word in translations:
                    chinese_words.append(translations[word])
                else:
                    chinese_words.append(word.title())
            
            chinese_pattern = ''.join(chinese_words)
            return {'name': chinese_pattern, 'description': f"{indicator_name}æŒ‡æ ‡æ˜¾ç¤º{chinese_pattern}å½¢æ€"}
        
        # 4. å¤„ç†å…¶ä»–å¸¸è§æŒ‡æ ‡
        if indicator_name == 'PSY':
            if pattern == 'PSY_CROSS_DOWN_50':
                return {'name': 'PSYä¸‹ç©¿50', 'description': 'PSYå¿ƒç†çº¿ä¸‹ç©¿50æ°´å¹³çº¿ï¼Œå¸‚åœºæƒ…ç»ªè½¬å¼±'}
            elif pattern == 'PSY_BELOW_50':
                return {'name': 'PSYå¿ƒç†çº¿50ä¸‹æ–¹', 'description': 'PSYå¿ƒç†çº¿ä½äº50ä¸‹æ–¹ï¼Œå¸‚åœºæƒ…ç»ªåæ‚²è§‚'}
            elif pattern == 'PSY_BELOW_MA':
                return {'name': 'PSYå‡çº¿ä¸‹æ–¹', 'description': 'PSYå¿ƒç†çº¿ä½äºç§»åŠ¨å¹³å‡çº¿ä¸‹æ–¹'}
            elif pattern == 'PSY_STRONG_DOWN':
                return {'name': 'PSYå¼ºåŠ¿ä¸‹è·Œ', 'description': 'PSYå¿ƒç†çº¿å¼ºåŠ¿ä¸‹è·Œï¼Œå¸‚åœºæƒ…ç»ªæ‚²è§‚'}
            elif pattern == 'PSY_ABOVE_50':
                return {'name': 'PSYå¿ƒç†çº¿50ä¸Šæ–¹', 'description': 'PSYå¿ƒç†çº¿ä½äº50ä¸Šæ–¹ï¼Œå¸‚åœºæƒ…ç»ªåä¹è§‚'}
            elif pattern == 'PSY_ABOVE_MA':
                return {'name': 'PSYå‡çº¿ä¸Šæ–¹', 'description': 'PSYå¿ƒç†çº¿ä½äºç§»åŠ¨å¹³å‡çº¿ä¸Šæ–¹'}
            elif pattern == 'PSY_DEATH_CROSS':
                return {'name': 'PSYæ­»å‰', 'description': 'PSYå¿ƒç†çº¿å½¢æˆæ­»å‰'}
        
        elif indicator_name == 'Vortex':
            if pattern == 'VORTEX_BULLISH_CROSS':
                return {'name': 'æ¶¡æ—‹æŒ‡æ ‡é‡‘å‰', 'description': 'VI+ä¸Šç©¿VI-ï¼Œå½¢æˆé‡‘å‰ä¿¡å·ï¼Œçœ‹æ¶¨'}
            elif pattern == 'VORTEX_VI_PLUS_ABOVE':
                return {'name': 'æ¶¡æ—‹æ­£å€¼å¤§äºè´Ÿå€¼', 'description': 'VI+å¤§äºVI-ï¼Œå¤šå¤´å ä¼˜åŠ¿'}
            elif pattern == 'VORTEX_VI_MINUS_ABOVE':
                return {'name': 'æ¶¡æ—‹è´Ÿå€¼å¤§äºæ­£å€¼', 'description': 'VI-å¤§äºVI+ï¼Œç©ºå¤´å ä¼˜åŠ¿'}
            elif pattern == 'VORTEX_VI_MINUS_RISING':
                return {'name': 'æ¶¡æ—‹è´Ÿå€¼ä¸Šå‡', 'description': 'VI-å€¼æŒç»­ä¸Šå‡ï¼Œç©ºå¤´åŠ›é‡å¢å¼º'}
            elif pattern == 'VORTEX_VI_MINUS_UPTREND':
                return {'name': 'æ¶¡æ—‹è´Ÿå€¼ä¸Šå‡è¶‹åŠ¿', 'description': 'VI-å€¼å‘ˆä¸Šå‡è¶‹åŠ¿ï¼Œç©ºå¤´åŠ›é‡é€æ¸å¢å¼º'}
        
        elif indicator_name == 'EnhancedTRIX':
            if pattern.startswith('TRIXè¶‹åŠ¿è½¬æŠ˜') and description:
                if 'åŸºäº' in description and 'åˆ†æ:' in description:
                    parts = description.split('åˆ†æ:')
                    if len(parts) > 1:
                        specific_pattern = parts[1].strip()
                        if specific_pattern == 'above_zero':
                            return {'name': 'TRIXé›¶è½´ä¸Šæ–¹', 'description': 'TRIXä½äºé›¶è½´ä¸Šæ–¹ï¼Œé•¿æœŸè¶‹åŠ¿åå¤š'}
                        elif specific_pattern == 'below_zero':
                            return {'name': 'TRIXé›¶è½´ä¸‹æ–¹', 'description': 'TRIXä½äºé›¶è½´ä¸‹æ–¹ï¼Œé•¿æœŸè¶‹åŠ¿åç©º'}
                        elif specific_pattern == 'falling':
                            return {'name': 'TRIXä¸‹é™', 'description': 'TRIXæŒ‡æ ‡ä¸‹é™ï¼Œé•¿æœŸåŠ¨é‡å‡å¼±'}
                        elif specific_pattern == 'rising':
                            return {'name': 'TRIXä¸Šå‡', 'description': 'TRIXæŒ‡æ ‡ä¸Šå‡ï¼Œé•¿æœŸåŠ¨é‡å¢å¼º'}
                        elif specific_pattern == 'acceleration':
                            return {'name': 'TRIXåŠ é€Ÿä¸Šå‡', 'description': 'TRIXæŒ‡æ ‡åŠ é€Ÿä¸Šå‡ï¼Œè¡¨æ˜ä»·æ ¼ä¸Šæ¶¨åŠ¨èƒ½ä¸æ–­å¢å¼º'}
                        elif specific_pattern == 'strong_bullish_consensus':
                            return {'name': 'TRIXå¼ºçƒˆçœ‹æ¶¨å…±æŒ¯', 'description': 'TRIXå¤šé‡ä¿¡å·å…±æŒ¯ï¼Œå½¢æˆå¼ºçƒˆçœ‹æ¶¨æ€åŠ¿'}
                        elif specific_pattern == 'deceleration':
                            return {'name': 'TRIXå‡é€Ÿ', 'description': 'TRIXæŒ‡æ ‡å‡é€Ÿå˜åŒ–ï¼ŒåŠ¨èƒ½è½¬å˜'}
        
        # 5. å¦‚æœæ˜¯æŠ€æœ¯æŒ‡æ ‡åˆ†æï¼Œå°è¯•æå–æ›´å…·ä½“çš„å½¢æ€æè¿°
        if pattern in ['æŠ€æœ¯æŒ‡æ ‡åˆ†æ', 'Technical Analysis', 'æŒ‡æ ‡åˆ†æ'] and description:
            if 'åŸºäº' in description and 'åˆ†æ:' in description:
                parts = description.split('åˆ†æ:')
                if len(parts) > 1:
                    specific_pattern = parts[1].strip()
                    if specific_pattern and len(specific_pattern) <= 30:
                        return {'name': specific_pattern, 'description': f"{indicator_name}æŒ‡æ ‡{specific_pattern}å½¢æ€"}
        
        # 5. å¤„ç†å½¢æ€åç§°ä¸­çš„å¸¸è§æ ¼å¼é—®é¢˜
        if pattern.endswith("å½¢æ€"):
            # å¦‚æœå½¢æ€åç§°ä»¥"å½¢æ€"ç»“å°¾ä¸”åŒ…å«ä¸‹åˆ’çº¿ï¼Œè¯´æ˜å¯èƒ½æ˜¯æœªæ˜ å°„çš„ä»£ç å½¢å¼
            if "_" in pattern or pattern.isupper():
                # å°è¯•å°†å…¶è½¬æ¢ä¸ºæ›´å¯è¯»çš„å½¢å¼
                readable_pattern = pattern.replace("_", " ").title()
                pattern = readable_pattern.replace("å½¢æ€", "")
                return {'name': pattern, 'description': f"{indicator_name}æŒ‡æ ‡{pattern}å½¢æ€"}
        
        # 6. å¦‚æœæ²¡æœ‰æ‰¾åˆ°åŒ¹é…é¡¹ï¼Œåˆ™ä½¿ç”¨åŸå§‹ä¿¡æ¯
        if not description:
            description = f"{indicator_name}æŒ‡æ ‡çš„{pattern}æŠ€æœ¯åˆ†æ"
        
        return {'name': pattern, 'description': description}

    def generate_strategy(self, 
                       common_indicators: Dict[str, List[Dict[str, Any]]],
                       strategy_name: str = "BuyPointCommonStrategy") -> Dict[str, Any]:
        """
        ç”Ÿæˆé€‰è‚¡ç­–ç•¥
        
        Args:
            common_indicators: å…±æ€§æŒ‡æ ‡
            strategy_name: ç­–ç•¥åç§°
            
        Returns:
            Dict[str, Any]: ç”Ÿæˆçš„ç­–ç•¥
        """
        try:
            # å¦‚æœæ²¡æœ‰å…±æ€§æŒ‡æ ‡ï¼Œè¿”å›ç©ºå­—å…¸
            if not common_indicators:
                return {}
                
            # æ„å»ºç­–ç•¥æ¡ä»¶
            strategy_conditions = []
            
            # éå†å„å‘¨æœŸçš„å…±æ€§æŒ‡æ ‡
            for period, indicators in common_indicators.items():
                # éå†è¯¥å‘¨æœŸä¸‹çš„å…±æ€§æŒ‡æ ‡
                for indicator in indicators:
                    # æ ¹æ®æŒ‡æ ‡ç±»å‹æ„å»ºæ¡ä»¶
                    if indicator['type'] == 'indicator':
                        # æŠ€æœ¯æŒ‡æ ‡å½¢æ€
                        condition = {
                            'type': 'indicator',
                            'period': period,
                            'indicator': indicator['name'],
                            'pattern': indicator['pattern'],
                            'score_threshold': indicator['avg_score'] * 0.8  # è®¾ç½®åˆ†æ•°é˜ˆå€¼ä¸ºå¹³å‡åˆ†çš„80%
                        }
                    else:  # patternç±»å‹
                        # Kçº¿å½¢æ€
                        condition = {
                            'type': 'pattern',
                            'period': period,
                            'pattern': indicator['name'],
                            'score_threshold': indicator['avg_score'] * 0.8  # è®¾ç½®åˆ†æ•°é˜ˆå€¼ä¸ºå¹³å‡åˆ†çš„80%
                        }
                        
                    strategy_conditions.append(condition)
            
            # ç”Ÿæˆç­–ç•¥
            strategy = self.strategy_generator.generate_strategy(
                strategy_name=strategy_name,
                conditions=strategy_conditions,
                condition_logic="OR"  # ä½¿ç”¨ORé€»è¾‘ï¼Œæ»¡è¶³ä»»ä¸€æ¡ä»¶å³å¯
            )
            
            return strategy
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆé€‰è‚¡ç­–ç•¥æ—¶å‡ºé”™: {e}")
            return {}
    
    def save_results(self, output_dir: str, results: List[Dict[str, Any]],
                    strategy: Dict[str, Any] = None, validation_result: Dict[str, Any] = None) -> None:
        """
        ä¿å­˜åˆ†æç»“æœ

        Args:
            output_dir: è¾“å‡ºç›®å½•
            results: åˆ†æç»“æœåˆ—è¡¨
            strategy: ç”Ÿæˆçš„ç­–ç•¥é…ç½®
            validation_result: ç­–ç•¥éªŒè¯ç»“æœ
        """
        try:
            # åˆ›å»ºè¾“å‡ºç›®å½•
            os.makedirs(output_dir, exist_ok=True)
            
            # ä¿å­˜åŸå§‹ç»“æœ
            results_file = os.path.join(output_dir, 'analysis_results.json')
            with open(results_file, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2, cls=CustomJSONEncoder)

            # P0çº§ä»»åŠ¡ï¼šä¿å­˜ç­–ç•¥å’ŒéªŒè¯ç»“æœ
            if strategy:
                strategy_file = os.path.join(output_dir, 'generated_strategy.json')
                with open(strategy_file, 'w', encoding='utf-8') as f:
                    json.dump(strategy, f, ensure_ascii=False, indent=2, cls=CustomJSONEncoder)
                logger.info(f"ç­–ç•¥é…ç½®å·²ä¿å­˜: {strategy_file}")

            if validation_result:
                validation_file = os.path.join(output_dir, 'validation_report.json')
                with open(validation_file, 'w', encoding='utf-8') as f:
                    json.dump(validation_result, f, ensure_ascii=False, indent=2, cls=CustomJSONEncoder)

                # ç”Ÿæˆå¯è¯»çš„éªŒè¯æŠ¥å‘Š
                validation_md_file = os.path.join(output_dir, 'validation_report.md')
                self.buypoint_validator.generate_validation_report(validation_result, validation_md_file)
                logger.info(f"éªŒè¯æŠ¥å‘Šå·²ä¿å­˜: {validation_md_file}")
                
            # æå–å…±æ€§æŒ‡æ ‡
            common_indicators = self.extract_common_indicators(results)
            if common_indicators:
                # ç”Ÿæˆå…±æ€§æŒ‡æ ‡æŠ¥å‘Š
                report_file = os.path.join(output_dir, 'common_indicators_report.md')
                self._generate_indicators_report(common_indicators, report_file)
                
                # ç”Ÿæˆç­–ç•¥é…ç½®
                strategy_file = os.path.join(output_dir, 'generated_strategy.json')
                strategy_config = self.generate_strategy(common_indicators)
                with open(strategy_file, 'w', encoding='utf-8') as f:
                    json.dump(strategy_config, f, ensure_ascii=False, indent=2, cls=CustomJSONEncoder)
            else:
                logger.warning("æœªèƒ½æå–åˆ°å…±æ€§æŒ‡æ ‡")
                
                # åˆ›å»ºç©ºçš„æŠ¥å‘Šå’Œç­–ç•¥æ–‡ä»¶
                report_file = os.path.join(output_dir, 'common_indicators_report.md')
                with open(report_file, 'w', encoding='utf-8') as f:
                    f.write("# ä¹°ç‚¹åˆ†ææŠ¥å‘Š\n\næœªèƒ½æå–åˆ°å…±æ€§æŒ‡æ ‡ï¼Œè¯·æ£€æŸ¥è¾“å…¥çš„ä¹°ç‚¹æ•°æ®ã€‚\n")
                    
                strategy_file = os.path.join(output_dir, 'generated_strategy.json')
                with open(strategy_file, 'w', encoding='utf-8') as f:
                    json.dump({"strategy": "æ— æ³•ç”Ÿæˆç­–ç•¥ï¼Œæœªæ‰¾åˆ°å…±æ€§æŒ‡æ ‡"}, f, ensure_ascii=False, indent=2)
                
        except Exception as e:
            logger.error(f"ä¿å­˜åˆ†æç»“æœæ—¶å‡ºé”™: {e}")
    
    def _generate_indicators_report(self, common_indicators: Dict[str, List[Dict[str, Any]]], report_file: str) -> None:
        """
        ç”Ÿæˆå…±æ€§æŒ‡æ ‡æŠ¥å‘Š

        Args:
            common_indicators: å…±æ€§æŒ‡æ ‡
            report_file: æŠ¥å‘Šæ–‡ä»¶è·¯å¾„
        """
        try:
            # æ„å»ºæŠ¥å‘Šå†…å®¹
            report = ["# ä¹°ç‚¹å…±æ€§æŒ‡æ ‡åˆ†ææŠ¥å‘Š\n\n"]

            # æ·»åŠ æŠ¥å‘Šæ¦‚è§ˆ
            report.append("## ğŸ“Š æŠ¥å‘Šæ¦‚è§ˆ\n\n")
            report.append(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}  \n")
            report.append("**åˆ†æç³»ç»Ÿ**: è‚¡ç¥¨åˆ†æç³»ç»Ÿ v2.1 (æ•°æ®æ±¡æŸ“ä¿®å¤ç‰ˆ)  \n")
            report.append("**æŠ€æœ¯æŒ‡æ ‡**: åŸºäº86ä¸ªä¸“ä¸šæŠ€æœ¯æŒ‡æ ‡  \n")
            report.append("**åˆ†æç®—æ³•**: ZXMä½“ç³»ä¹°ç‚¹æ£€æµ‹ç®—æ³•  \n")
            report.append("**ä¿®å¤çŠ¶æ€**: âœ… å·²ä¿®å¤æ—¶é—´å‘¨æœŸæ··ä¹±ã€è¯„åˆ†å¼‚å¸¸ã€å½¢æ€æè¿°ç­‰é—®é¢˜\n\n")

            report.append("## ğŸ“‹ åˆ†æè¯´æ˜\n\n")
            report.append("æœ¬æŠ¥å‘ŠåŸºäºZXMä¹°ç‚¹åˆ†æç³»ç»Ÿï¼Œå¯¹ä¸åŒæ—¶é—´å‘¨æœŸçš„å…±æ€§æŒ‡æ ‡è¿›è¡Œç»Ÿè®¡åˆ†æã€‚é€šè¿‡å¯¹ä¹°ç‚¹æ ·æœ¬çš„æ·±åº¦æŒ–æ˜ï¼Œè¯†åˆ«å‡ºåœ¨ä¹°ç‚¹å½¢æˆè¿‡ç¨‹ä¸­å…·æœ‰å…±æ€§ç‰¹å¾çš„æŠ€æœ¯æŒ‡æ ‡ï¼Œä¸ºæŠ•èµ„å†³ç­–æä¾›æ•°æ®æ”¯æ’‘ã€‚\n\n")

            report.append("**é‡è¦ä¿®å¤è¯´æ˜**ï¼š\n")
            report.append("- âœ… ä¿®å¤äº†æ—¶é—´å‘¨æœŸæ•°æ®æ··ä¹±é—®é¢˜ï¼Œç¡®ä¿æ¯ä¸ªå‘¨æœŸåªåŒ…å«å¯¹åº”çš„å½¢æ€æ•°æ®\n")
            report.append("- âœ… ä¿®å¤äº†è¯„åˆ†æ•°æ®å¼‚å¸¸é—®é¢˜ï¼Œé‡æ–°è®¡ç®—äº†åˆç†çš„å¹³å‡å¾—åˆ†\n")
            report.append("- âœ… ä¼˜åŒ–äº†å½¢æ€æè¿°ï¼Œä½¿ç”¨æ ‡å‡†æŠ€æœ¯åˆ†ææœ¯è¯­\n")
            report.append("- âœ… å¢å¼ºäº†æ•°æ®éªŒè¯ï¼Œç¡®ä¿æŠ¥å‘Šçš„å‡†ç¡®æ€§å’Œä¸€è‡´æ€§\n\n")

            report.append("### ğŸ¯ å…³é”®æŒ‡æ ‡è¯´æ˜\n")
            report.append("- **å‘½ä¸­ç‡**: åŒ…å«è¯¥æŒ‡æ ‡çš„è‚¡ç¥¨æ•°é‡å æ€»è‚¡ç¥¨æ•°é‡çš„æ¯”ä¾‹ (åŒ…å«è¯¥æŒ‡æ ‡çš„å”¯ä¸€è‚¡ç¥¨æ•°/æ€»è‚¡ç¥¨æ•° Ã— 100%)\n")
            report.append("- **å‘½ä¸­æ•°é‡**: åŒ…å«è¯¥æŒ‡æ ‡å½¢æ€çš„å”¯ä¸€è‚¡ç¥¨æ•°é‡ï¼ˆæ¯ä¸ªè‚¡ç¥¨åªè®¡ç®—ä¸€æ¬¡ï¼‰\n")
            report.append("- **å¹³å‡å¾—åˆ†**: è¯¥æŒ‡æ ‡åœ¨ä¹°ç‚¹åˆ†æä¸­çš„å¹³å‡è¯„åˆ† (0-100åˆ†åˆ¶ï¼Œå·²ä¿®å¤è®¡ç®—é€»è¾‘)\n\n")

            # è®¡ç®—æ€»ä½“ç»Ÿè®¡
            total_indicators = sum(len(indicators) for indicators in common_indicators.values())
            total_periods = len(common_indicators)

            # è®¡ç®—æ€»ä¹°ç‚¹æ•°é‡ - ä»å…±æ€§æŒ‡æ ‡æ•°æ®ä¸­æ¨æ–­
            total_samples = 0
            if common_indicators:
                # ä»ç¬¬ä¸€ä¸ªå‘¨æœŸçš„ç¬¬ä¸€ä¸ªæŒ‡æ ‡ä¸­è·å–æ€»ä¹°ç‚¹æ•°é‡
                first_period = next(iter(common_indicators.values()))
                if first_period:
                    first_indicator = first_period[0]
                    # ä»å‘½ä¸­ç‡å’Œå‘½ä¸­æ•°é‡åæ¨æ€»æ ·æœ¬æ•°
                    if first_indicator.get('hit_ratio', 0) > 0:
                        total_samples = int(first_indicator['hit_count'] / first_indicator['hit_ratio'])
                    else:
                        total_samples = first_indicator.get('hit_count', 0)

            # æ·»åŠ å„å‘¨æœŸçš„å…±æ€§æŒ‡æ ‡
            for period, indicators in common_indicators.items():

                report.append(f"## ğŸ“ˆ {period} å‘¨æœŸå…±æ€§æŒ‡æ ‡\n\n")

                # æ·»åŠ æ•°æ®ç»Ÿè®¡
                report.append("### æ•°æ®ç»Ÿè®¡\n")
                report.append(f"- **æ€»æ ·æœ¬æ•°é‡**: {total_samples}ä¸ªä¹°ç‚¹æ ·æœ¬\n")
                report.append(f"- **å…±æ€§æŒ‡æ ‡æ•°é‡**: {len(indicators)}ä¸ªæŒ‡æ ‡å½¢æ€\n")
                report.append(f"- **åˆ†æå‘¨æœŸ**: {period}Kçº¿\n\n")

                # æŒ‰å‘½ä¸­ç‡å’Œå¹³å‡å¾—åˆ†æ’åº
                sorted_indicators = sorted(indicators, key=lambda x: (x['hit_ratio'], x['avg_score']), reverse=True)

                # æ·»åŠ è¡¨æ ¼å¤´
                report.append("| æŒ‡æ ‡ç±»å‹ | æŒ‡æ ‡åç§° | å½¢æ€ | å½¢æ€æè¿° | å‘½ä¸­ç‡ | å‘½ä¸­æ•°é‡ | å¹³å‡å¾—åˆ† |\n")
                report.append("|---------|----------|------|----------|--------|----------|----------|\n")

                # æ·»åŠ å„æŒ‡æ ‡ä¿¡æ¯
                for indicator in sorted_indicators:
                    indicator_type = indicator['type']
                    indicator_name = indicator['name']
                    pattern = indicator.get('pattern', '-')

                    # è·å–å½¢æ€æè¿°
                    description = ""
                    if 'hits' in indicator and indicator['hits']:
                        # ä»ç¬¬ä¸€ä¸ªhitä¸­è·å–æè¿°ä¿¡æ¯
                        first_hit = indicator['hits'][0]
                        if 'details' in first_hit:
                            description = first_hit['details'].get('description', '')

                    # ä½¿ç”¨å®Œæ•´çš„æŒ‡æ ‡å½¢æ€æ˜ å°„è¿›è¡Œä¼˜åŒ–
                    pattern_info = self.get_precise_pattern_info(indicator_name, pattern, description)
                    pattern = pattern_info['name']
                    description = pattern_info['description']

                    # æ¸…ç†æè¿°ä¸­çš„æ¢è¡Œç¬¦å’Œç‰¹æ®Šå­—ç¬¦ï¼Œé¿å…ç ´åè¡¨æ ¼æ ¼å¼
                    description = description.replace('\n', ' ').replace('|', 'ï½œ').strip()

                    # å‘½ä¸­ç‡ç°åœ¨å·²ç»æ­£ç¡®è®¡ç®—ï¼Œç›´æ¥ä½¿ç”¨
                    hit_ratio = indicator['hit_ratio']
                    # éªŒè¯å‘½ä¸­ç‡åœ¨æ­£ç¡®èŒƒå›´å†…
                    assert 0.0 <= hit_ratio <= 1.0, f"æŠ¥å‘Šç”Ÿæˆæ—¶å‘ç°æ— æ•ˆå‘½ä¸­ç‡: {hit_ratio:.3f}"

                    hit_ratio_str = f"{hit_ratio:.1%}"
                    hit_count = indicator['hit_count']

                    # ä½¿ç”¨å·²è®¡ç®—çš„å¹³å‡å¾—åˆ†
                    avg_score = indicator['avg_score']
                    avg_score_str = f"{avg_score:.1f}"

                    report.append(f"| {indicator_type} | {indicator_name} | {pattern} | {description} | {hit_ratio_str} | {hit_count} | {avg_score_str} |\n")

                # æ·»åŠ å‘¨æœŸåˆ†ææ€»ç»“
                if sorted_indicators:
                    high_hit_indicators = [ind for ind in sorted_indicators if ind['hit_ratio'] >= 0.8]
                    medium_hit_indicators = [ind for ind in sorted_indicators if 0.6 <= ind['hit_ratio'] < 0.8]
                    low_hit_indicators = [ind for ind in sorted_indicators if ind['hit_ratio'] < 0.6]

                    report.append(f"\n### ğŸ“Š {period}å‘¨æœŸåˆ†ææ€»ç»“\n\n")

                    if high_hit_indicators:
                        report.append(f"#### ğŸ¯ é«˜å‘½ä¸­ç‡æŒ‡æ ‡ (â‰¥80%)\n")
                        for ind in high_hit_indicators[:5]:  # æ˜¾ç¤ºå‰5ä¸ª
                            hit_ratio = ind['hit_ratio']
                            pattern = ind.get('pattern', '')
                            indicator_name = ind['name']

                            # è·å–å½¢æ€æè¿°
                            description = ""
                            if 'hits' in ind and ind['hits']:
                                first_hit = ind['hits'][0]
                                if 'details' in first_hit:
                                    description = first_hit['details'].get('description', '')

                            # ä½¿ç”¨å®Œæ•´çš„æŒ‡æ ‡å½¢æ€æ˜ å°„è¿›è¡Œä¼˜åŒ–ï¼ˆä¸ä¸Šé¢çš„é€»è¾‘ä¿æŒä¸€è‡´ï¼‰
                            pattern_info = self.get_precise_pattern_info(indicator_name, pattern, description)
                            pattern = pattern_info['name']
                            description = pattern_info['description']

                            if not description:
                                description = f"{indicator_name}æŒ‡æ ‡çš„{pattern}æŠ€æœ¯åˆ†æ"
                            description = description.replace('\n', ' ').strip()

                            report.append(f"- **{indicator_name}** ({pattern}): {hit_ratio:.1%}å‘½ä¸­ç‡ï¼Œå¹³å‡å¾—åˆ†{ind['avg_score']:.1f}åˆ†\n")
                            report.append(f"  *{description}*\n")
                        report.append("\n")

                    if medium_hit_indicators:
                        report.append(f"#### ğŸ”„ ä¸­ç­‰å‘½ä¸­ç‡æŒ‡æ ‡ (60-80%)\n")
                        for ind in medium_hit_indicators[:3]:  # æ˜¾ç¤ºå‰3ä¸ª
                            hit_ratio = ind['hit_ratio']
                            pattern = ind.get('pattern', '')
                            indicator_name = ind['name']

                            # è·å–å½¢æ€æè¿°
                            description = ""
                            if 'hits' in ind and ind['hits']:
                                first_hit = ind['hits'][0]
                                if 'details' in first_hit:
                                    description = first_hit['details'].get('description', '')

                            # ä½¿ç”¨å®Œæ•´çš„æŒ‡æ ‡å½¢æ€æ˜ å°„è¿›è¡Œä¼˜åŒ–ï¼ˆä¸ä¸Šé¢çš„é€»è¾‘ä¿æŒä¸€è‡´ï¼‰
                            pattern_info = self.get_precise_pattern_info(indicator_name, pattern, description)
                            pattern = pattern_info['name']
                            description = pattern_info['description']

                            if not description:
                                description = f"{indicator_name}æŒ‡æ ‡çš„{pattern}æŠ€æœ¯åˆ†æ"
                            description = description.replace('\n', ' ').strip()

                            report.append(f"- **{indicator_name}** ({pattern}): {hit_ratio:.1%}å‘½ä¸­ç‡ï¼Œå¹³å‡å¾—åˆ†{ind['avg_score']:.1f}åˆ†\n")
                            report.append(f"  *{description}*\n")
                        report.append("\n")

                report.append("---\n\n")

            # æ·»åŠ ç»¼åˆåˆ†æ
            if total_indicators > 0:
                report.append("## ğŸ¯ ç»¼åˆåˆ†ææ€»ç»“\n\n")
                report.append(f"### ğŸ“Š æ•´ä½“ç»Ÿè®¡\n")
                report.append(f"- **åˆ†æå‘¨æœŸæ•°**: {total_periods}ä¸ªæ—¶é—´å‘¨æœŸ\n")
                report.append(f"- **å…±æ€§æŒ‡æ ‡æ€»æ•°**: {total_indicators}ä¸ªæŒ‡æ ‡å½¢æ€\n")
                report.append(f"- **æŠ€æœ¯æŒ‡æ ‡è¦†ç›–**: åŸºäº86ä¸ªä¸“ä¸šæŠ€æœ¯æŒ‡æ ‡\n")
                report.append(f"- **åˆ†æç®—æ³•**: ZXMä½“ç³»ä¸“ä¸šä¹°ç‚¹æ£€æµ‹\n\n")

                report.append("### ğŸ’¡ åº”ç”¨å»ºè®®\n")
                report.append("1. **ä¼˜å…ˆå…³æ³¨é«˜å‘½ä¸­ç‡æŒ‡æ ‡**: å‘½ä¸­ç‡â‰¥80%çš„æŒ‡æ ‡å…·æœ‰è¾ƒå¼ºçš„ä¹°ç‚¹é¢„æµ‹èƒ½åŠ›\n")
                report.append("2. **ç»“åˆå¤šå‘¨æœŸåˆ†æ**: ä¸åŒå‘¨æœŸçš„æŒ‡æ ‡å¯ä»¥æä¾›ä¸åŒå±‚é¢çš„ä¹°ç‚¹ç¡®è®¤\n")
                report.append("3. **æ³¨é‡å¹³å‡å¾—åˆ†**: é«˜å¾—åˆ†æŒ‡æ ‡é€šå¸¸ä»£è¡¨æ›´é«˜è´¨é‡çš„ä¹°ç‚¹ä¿¡å·\n")
                report.append("4. **ZXMä½“ç³»ä¼˜å…ˆ**: ZXMç³»åˆ—æŒ‡æ ‡ç»è¿‡ä¸“ä¸šä¼˜åŒ–ï¼Œå…·æœ‰æ›´é«˜çš„å®æˆ˜ä»·å€¼\n\n")

            # æ·»åŠ æŠ€æœ¯æ”¯æŒä¿¡æ¯
            report.append("---\n\n")
            report.append("## ğŸ“ æŠ€æœ¯æ”¯æŒ\n\n")
            report.append("### ğŸ”§ ç³»ç»Ÿæ€§èƒ½\n")
            report.append("- **åˆ†æé€Ÿåº¦**: 0.05ç§’/è‚¡ (99.9%æ€§èƒ½ä¼˜åŒ–)\n")
            report.append("- **æŒ‡æ ‡è¦†ç›–**: 86ä¸ªä¸“ä¸šæŠ€æœ¯æŒ‡æ ‡\n")
            report.append("- **ç®—æ³•åŸºç¡€**: ZXMä½“ç³»ä¸“ä¸šä¹°ç‚¹æ£€æµ‹\n")
            report.append("- **å¤„ç†èƒ½åŠ›**: 72,000è‚¡/å°æ—¶\n\n")

            report.append("### ğŸ“š ç›¸å…³æ–‡æ¡£\n")
            report.append("- **ç”¨æˆ·æŒ‡å—**: [docs/user_guide.md](../docs/user_guide.md)\n")
            report.append("- **æŠ€æœ¯æŒ‡æ ‡**: [docs/modules/indicators.md](../docs/modules/indicators.md)\n")
            report.append("- **ä¹°ç‚¹åˆ†æ**: [docs/modules/buypoint_analysis.md](../docs/modules/buypoint_analysis.md)\n")
            report.append("- **APIæ–‡æ¡£**: [docs/api_reference.md](../docs/api_reference.md)\n\n")

            report.append("---\n\n")
            report.append(f"*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*  \n")
            report.append("*åˆ†æç³»ç»Ÿ: è‚¡ç¥¨åˆ†æç³»ç»Ÿ v2.0*  \n")
            report.append("*æŠ€æœ¯æ”¯æŒ: åŸºäº86ä¸ªæŠ€æœ¯æŒ‡æ ‡å’ŒZXMä¸“ä¸šä½“ç³»*\n")

            # å†™å…¥æŠ¥å‘Šæ–‡ä»¶
            with open(report_file, 'w', encoding='utf-8') as f:
                f.writelines(report)

        except Exception as e:
            logger.error(f"ç”Ÿæˆå…±æ€§æŒ‡æ ‡æŠ¥å‘Šæ—¶å‡ºé”™: {e}")
    
    def run_analysis(self,
                  input_csv: str,
                  output_dir: str,
                  min_hit_ratio: float = 0.6,
                  strategy_name: str = "BuyPointCommonStrategy",
                  filter_negative_patterns: bool = True):
        """
        è¿è¡Œä¹°ç‚¹æ‰¹é‡åˆ†æ

        Args:
            input_csv: è¾“å…¥CSVæ–‡ä»¶è·¯å¾„
            output_dir: è¾“å‡ºç›®å½•
            min_hit_ratio: æœ€å°å‘½ä¸­æ¯”ä¾‹
            strategy_name: ç”Ÿæˆçš„ç­–ç•¥åç§°
            filter_negative_patterns: æ˜¯å¦è¿‡æ»¤è´Ÿé¢æ¨¡å¼
        """
        # P1çº§ä»»åŠ¡ï¼šä½¿ç”¨ç›‘æ§è£…é¥°å™¨åŒ…è£…æ ¸å¿ƒåˆ†æé€»è¾‘
        @self.system_monitor.monitor_analysis_performance
        def _run_monitored_analysis():
            return self._execute_core_analysis(input_csv, output_dir, min_hit_ratio, strategy_name, filter_negative_patterns)

        # æ‰§è¡Œè¢«ç›‘æ§çš„åˆ†æ
        result = _run_monitored_analysis()

        # P1çº§ä»»åŠ¡ï¼šç”Ÿæˆç³»ç»Ÿå¥åº·æŠ¥å‘Š
        try:
            health_report_file = os.path.join(output_dir, 'system_health_report.md')
            self.system_monitor.generate_health_report(health_report_file)
            logger.info(f"ç³»ç»Ÿå¥åº·æŠ¥å‘Šå·²ç”Ÿæˆ: {health_report_file}")
        except Exception as e:
            logger.warning(f"ç”Ÿæˆç³»ç»Ÿå¥åº·æŠ¥å‘Šå¤±è´¥: {e}")

        return result

    def _execute_core_analysis(self, input_csv: str, output_dir: str,
                             min_hit_ratio: float, strategy_name: str,
                             filter_negative_patterns: bool):
        """æ‰§è¡Œæ ¸å¿ƒåˆ†æé€»è¾‘"""
        try:
            # åŠ è½½ä¹°ç‚¹æ•°æ®
            buypoints_df = self.load_buypoints_from_csv(input_csv)
            if buypoints_df.empty:
                logger.error(f"æœªèƒ½åŠ è½½ä¹°ç‚¹æ•°æ®ï¼Œåˆ†æç»ˆæ­¢")
                return
                
            # æ‰¹é‡åˆ†æä¹°ç‚¹
            buypoint_results = self.analyze_batch_buypoints(buypoints_df)
            if not buypoint_results:
                logger.error(f"ä¹°ç‚¹åˆ†ææœªäº§ç”Ÿç»“æœï¼Œåˆ†æç»ˆæ­¢")
                return
                
            # æå–å…±æ€§æŒ‡æ ‡
            common_indicators = self.extract_common_indicators(
                buypoint_results=buypoint_results,
                min_hit_ratio=min_hit_ratio,
                filter_negative_patterns=filter_negative_patterns
            )
            if not common_indicators:
                logger.warning(f"æœªèƒ½æå–åˆ°å…±æ€§æŒ‡æ ‡")
                
            # ç”Ÿæˆé€‰è‚¡ç­–ç•¥
            strategy = self.generate_strategy(
                common_indicators=common_indicators,
                strategy_name=strategy_name
            )

            # P0çº§ä»»åŠ¡ï¼šæ·»åŠ é—­ç¯éªŒè¯æœºåˆ¶
            validation_result = None
            if strategy and strategy.get('conditions'):
                logger.info("å¼€å§‹æ‰§è¡Œç­–ç•¥é—­ç¯éªŒè¯")
                try:
                    # ä½¿ç”¨æœ€æ–°çš„ä¹°ç‚¹æ—¥æœŸä½œä¸ºéªŒè¯æ—¥æœŸ
                    validation_date = max(buypoints_df['buypoint_date'])

                    validation_result = self.buypoint_validator.validate_strategy_roundtrip(
                        original_buypoints=buypoints_df,
                        generated_strategy=strategy,
                        validation_date=validation_date
                    )

                    match_rate = validation_result['match_analysis'].get('match_rate', 0)
                    logger.info(f"ç­–ç•¥é—­ç¯éªŒè¯å®Œæˆï¼ŒåŒ¹é…ç‡: {match_rate:.2%}")

                    # P1çº§ä»»åŠ¡ï¼šå¦‚æœåŒ¹é…ç‡ä½äº60%ï¼Œè‡ªåŠ¨è§¦å‘ä¼˜åŒ–
                    if match_rate < 0.6:
                        logger.warning(f"ç­–ç•¥åŒ¹é…ç‡ {match_rate:.2%} ä½äºæœŸæœ›é˜ˆå€¼ 60%ï¼Œå¯åŠ¨æ™ºèƒ½ä¼˜åŒ–")

                        try:
                            optimization_result = self.strategy_optimizer.optimize_strategy(
                                original_strategy=strategy,
                                original_buypoints=buypoints_df,
                                validation_date=validation_date,
                                max_iterations=3
                            )

                            optimized_strategy = optimization_result.get('optimized_strategy')
                            improvement_summary = optimization_result.get('improvement_summary', {})

                            final_match_rate = improvement_summary.get('final_match_rate', match_rate)
                            improvement = improvement_summary.get('absolute_improvement', 0)

                            if improvement > 0:
                                logger.info(f"âœ… ç­–ç•¥ä¼˜åŒ–æˆåŠŸï¼åŒ¹é…ç‡ä» {match_rate:.2%} æå‡åˆ° {final_match_rate:.2%}")
                                strategy = optimized_strategy  # ä½¿ç”¨ä¼˜åŒ–åçš„ç­–ç•¥

                                # é‡æ–°éªŒè¯ä¼˜åŒ–åçš„ç­–ç•¥
                                final_validation = self.buypoint_validator.validate_strategy_roundtrip(
                                    original_buypoints=buypoints_df,
                                    generated_strategy=optimized_strategy,
                                    validation_date=validation_date
                                )
                                validation_result['optimization_result'] = optimization_result
                                validation_result['final_validation'] = final_validation
                            else:
                                logger.warning(f"ç­–ç•¥ä¼˜åŒ–æœªèƒ½æ˜¾è‘—æ”¹å–„åŒ¹é…ç‡")
                                validation_result['optimization_result'] = optimization_result

                        except Exception as opt_e:
                            logger.error(f"ç­–ç•¥ä¼˜åŒ–å¤±è´¥: {opt_e}")
                            validation_result['optimization_error'] = str(opt_e)
                    else:
                        logger.info(f"âœ… ç­–ç•¥åŒ¹é…ç‡ {match_rate:.2%} è¾¾åˆ°æœŸæœ›é˜ˆå€¼")

                except Exception as e:
                    logger.error(f"ç­–ç•¥é—­ç¯éªŒè¯å¤±è´¥: {e}")
                    validation_result = {'error': str(e)}

            # ä¿å­˜ç»“æœï¼ˆåŒ…å«éªŒè¯ç»“æœï¼‰
            self.save_results(output_dir, buypoint_results, strategy, validation_result)

            logger.info(f"ä¹°ç‚¹æ‰¹é‡åˆ†æå®Œæˆ")

            # è¿”å›åˆ†æç»“æœç”¨äºç›‘æ§
            return {
                'buypoint_count': len(buypoint_results),
                'strategy_generated': strategy is not None,
                'validation_result': validation_result,
                'match_analysis': validation_result.get('match_analysis', {}) if validation_result else {}
            }

        except Exception as e:
            logger.error(f"è¿è¡Œä¹°ç‚¹æ‰¹é‡åˆ†ææ—¶å‡ºé”™: {e}")
            raise

class CustomJSONEncoder(json.JSONEncoder):
    """è‡ªå®šä¹‰JSONç¼–ç å™¨ï¼Œå¤„ç†ç‰¹æ®Šæ•°æ®ç±»å‹"""
    
    def default(self, obj):
        # å¤„ç†NumPyç±»å‹
        if isinstance(obj, (np.integer, np.int64, np.int32, np.int16, np.int8)):
            return int(obj)
        elif isinstance(obj, (np.floating, np.float64, np.float32, np.float16)):
            return float(obj)
        elif isinstance(obj, np.ndarray):
            return obj.tolist()
        elif isinstance(obj, np.bool_):
            return bool(obj)
        # å¤„ç†æ—¥æœŸæ—¶é—´
        elif isinstance(obj, (pd.Timestamp, datetime.datetime, datetime.date)):
            return obj.isoformat()
        # å¤„ç†é›†åˆç±»å‹
        elif isinstance(obj, set):
            return list(obj)
        # å¤„ç†æ— æ³•åºåˆ—åŒ–çš„å¯¹è±¡
        try:
            return super().default(obj)
        except TypeError:
            return str(obj)  # è½¬æ¢ä¸ºå­—ç¬¦ä¸²ä½œä¸ºåå¤‡æ–¹æ¡ˆ 