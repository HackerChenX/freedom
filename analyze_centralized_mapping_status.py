#!/usr/bin/env python3
"""
é›†ä¸­å¼æ˜ å°„çŠ¶æ€åˆ†æå™¨ - åˆ†æCOMPLETE_INDICATOR_PATTERNS_MAPä¸­çš„é‡å¤å®šä¹‰å’Œè¿ç§»çŠ¶æ€
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from analysis.buypoints.buypoint_batch_analyzer import COMPLETE_INDICATOR_PATTERNS_MAP
from indicators.pattern_registry import PatternRegistry
from utils.logger import get_logger
import importlib

# è®¾ç½®æ—¥å¿—çº§åˆ«
import logging
logging.basicConfig(level=logging.INFO)
logger = get_logger(__name__)

class CentralizedMappingAnalyzer:
    """é›†ä¸­å¼æ˜ å°„çŠ¶æ€åˆ†æå™¨"""

    def __init__(self):
        self.registry = PatternRegistry()
        self._initialize_indicators()
        
        # å·²çŸ¥å·²å®ç°register_patterns()æ–¹æ³•çš„æŒ‡æ ‡
        self.indicators_with_patterns = {
            # æ ¸å¿ƒæŠ€æœ¯æŒ‡æ ‡
            'KDJ': 'indicators.kdj',
            'RSI': 'indicators.rsi', 
            'MACD': 'indicators.macd',
            'BOLL': 'indicators.boll',
            'MA': 'indicators.ma',
            'EMA': 'indicators.ema',
            
            # è¶‹åŠ¿æŒ‡æ ‡
            'SAR': 'indicators.sar',
            'ADX': 'indicators.adx',
            'DMI': 'indicators.dmi',
            
            # åŠ¨é‡æŒ‡æ ‡
            'TRIX': 'indicators.trix',
            'ROC': 'indicators.roc',
            'CMO': 'indicators.cmo',
            'STOCHRSI': 'indicators.stochrsi',
            'PSY': 'indicators.psy',
            'WR': 'indicators.wr',
            'BIAS': 'indicators.bias',
            
            # æˆäº¤é‡æŒ‡æ ‡
            'VOL': 'indicators.vol',
            'OBV': 'indicators.obv',
            'MFI': 'indicators.mfi',
            'EMV': 'indicators.emv',
            
            # æ³¢åŠ¨ç‡æŒ‡æ ‡
            'ATR': 'indicators.atr',
            'KC': 'indicators.kc',
            'Vortex': 'indicators.vortex',
            'CCI': 'indicators.cci',
        }
        
        # æŒ‡æ ‡ä¼˜å…ˆçº§åˆ†ç±»
        self.priority_classification = {
            'P0': ['KDJ', 'RSI', 'MACD', 'BOLL', 'MA', 'EMA'],  # æ ¸å¿ƒæŒ‡æ ‡
            'P1': ['SAR', 'ADX', 'DMI', 'TRIX', 'ROC', 'CMO'],  # é‡è¦æŒ‡æ ‡
            'P2': ['STOCHRSI', 'PSY', 'WR', 'BIAS', 'VOL', 'OBV', 'MFI', 'EMV'],  # å¸¸ç”¨æŒ‡æ ‡
            'P3': ['ATR', 'KC', 'Vortex', 'CCI', 'VOSC', 'VR', 'PVT'],  # ä¸“ä¸šæŒ‡æ ‡
            'P4': ['ZXMDailyMACD', 'ZXMTurnover', 'ZXMVolumeShrink', 'ZXMMACallback', 
                   'ZXMBuyPointScore', 'ZXMPattern', 'ZXMRiseElasticity', 'ZXMElasticityScore'],  # ZXMç³»åˆ—
            'P5': ['StockScoreCalculator', 'BounceDetector', 'TrendDetector', 'TrendDuration',
                   'AmplitudeElasticity', 'Elasticity', 'InstitutionalBehavior', 'ChipDistribution',
                   'SelectionModel', 'StockVIX']  # ç³»ç»Ÿåˆ†ææŒ‡æ ‡
        }

    def _initialize_indicators(self):
        """åˆå§‹åŒ–æ‰€æœ‰æŒ‡æ ‡ä»¥æ³¨å†Œå½¢æ€åˆ°PatternRegistry"""
        print("ğŸ”„ åˆå§‹åŒ–æŒ‡æ ‡å¹¶æ³¨å†Œå½¢æ€...")

        indicators_to_init = [
            ('indicators.kdj', 'KDJ'),
            ('indicators.rsi', 'RSI'),
            ('indicators.trix', 'TRIX'),
            ('indicators.roc', 'ROC'),
            ('indicators.cmo', 'CMO'),
            ('indicators.vol', 'VOL'),
            ('indicators.atr', 'ATR'),
            ('indicators.kc', 'KC'),
            ('indicators.mfi', 'MFI'),
            ('indicators.vortex', 'Vortex'),
            ('indicators.obv', 'OBV'),
            ('indicators.ma', 'MA'),
            ('indicators.ema', 'EMA'),
            ('indicators.cci', 'CCI'),
            ('indicators.sar', 'SAR'),
            ('indicators.adx', 'ADX'),
            ('indicators.psy', 'PSY'),
            ('indicators.bias', 'BIAS'),
            ('indicators.dmi', 'DMI'),
            ('indicators.emv', 'EMV'),
            ('indicators.wr', 'WR'),
        ]

        initialized_count = 0
        for module_name, class_name in indicators_to_init:
            try:
                module = importlib.import_module(module_name)
                indicator_class = getattr(module, class_name)

                # å°è¯•ä¸åŒçš„åˆå§‹åŒ–æ–¹å¼
                indicator = None
                try:
                    indicator = indicator_class()
                except:
                    try:
                        indicator = indicator_class(period=14)
                    except:
                        try:
                            indicator = indicator_class(periods=[5, 10, 20])
                        except:
                            pass

                if indicator and hasattr(indicator, 'register_patterns'):
                    indicator.register_patterns()
                    initialized_count += 1

            except Exception as e:
                pass  # é™é»˜å¤„ç†é”™è¯¯

        print(f"âœ… æˆåŠŸåˆå§‹åŒ–{initialized_count}ä¸ªæŒ‡æ ‡")

    def get_indicator_priority(self, indicator_name: str) -> str:
        """è·å–æŒ‡æ ‡ä¼˜å…ˆçº§"""
        for priority, indicators in self.priority_classification.items():
            if indicator_name in indicators:
                return priority
        return 'P6'  # æœªåˆ†ç±»
    
    def check_indicator_implementation(self, indicator_name: str) -> dict:
        """æ£€æŸ¥æŒ‡æ ‡æ˜¯å¦å·²å®ç°register_patterns()æ–¹æ³•"""
        result = {
            'has_implementation': False,
            'module_path': None,
            'patterns_count': 0,
            'error': None
        }

        # é¦–å…ˆæ£€æŸ¥PatternRegistryä¸­æ˜¯å¦å·²æœ‰è¯¥æŒ‡æ ‡çš„å½¢æ€
        patterns = self.registry.get_patterns_by_indicator(indicator_name)
        if patterns and len(patterns) > 0:
            result['has_implementation'] = True
            result['patterns_count'] = len(patterns)
            print(f"âœ… {indicator_name}: åœ¨PatternRegistryä¸­æ‰¾åˆ°{len(patterns)}ä¸ªå½¢æ€")

        # ç„¶åæ£€æŸ¥æ˜¯å¦æœ‰å¯¹åº”çš„æ¨¡å—å®ç°
        if indicator_name in self.indicators_with_patterns:
            module_path = self.indicators_with_patterns[indicator_name]
            result['module_path'] = module_path

            try:
                # å°è¯•å¯¼å…¥æ¨¡å—
                module = importlib.import_module(module_path)

                # æŸ¥æ‰¾æŒ‡æ ‡ç±»
                for attr_name in dir(module):
                    attr = getattr(module, attr_name)
                    if (hasattr(attr, '__bases__') and
                        hasattr(attr, 'register_patterns') and
                        callable(getattr(attr, 'register_patterns'))):

                        if not result['has_implementation']:
                            result['has_implementation'] = True
                            print(f"âœ… {indicator_name}: æ‰¾åˆ°register_patterns()æ–¹æ³•")
                        break

            except Exception as e:
                result['error'] = str(e)
                print(f"âš ï¸ {indicator_name}: æ¨¡å—å¯¼å…¥å¤±è´¥ - {e}")
        else:
            print(f"âŒ {indicator_name}: æœªæ‰¾åˆ°å¯¹åº”çš„æ¨¡å—å®ç°")

        return result
    
    def analyze_centralized_mapping(self) -> dict:
        """åˆ†æé›†ä¸­å¼æ˜ å°„çŠ¶æ€"""
        print("\n=== é›†ä¸­å¼æ˜ å°„çŠ¶æ€åˆ†æ ===")
        
        analysis_result = {
            'total_indicators': len(COMPLETE_INDICATOR_PATTERNS_MAP),
            'total_patterns': 0,
            'migrated_indicators': [],
            'duplicate_indicators': [],
            'unmigrated_indicators': [],
            'priority_distribution': {},
            'migration_recommendations': []
        }
        
        # ç»Ÿè®¡æ€»å½¢æ€æ•°é‡
        for indicator_name, patterns in COMPLETE_INDICATOR_PATTERNS_MAP.items():
            if isinstance(patterns, dict):
                analysis_result['total_patterns'] += len(patterns)
        
        print(f"ğŸ“Š é›†ä¸­å¼æ˜ å°„æ€»è§ˆ:")
        print(f"   æŒ‡æ ‡æ€»æ•°: {analysis_result['total_indicators']}")
        print(f"   å½¢æ€æ€»æ•°: {analysis_result['total_patterns']}")
        
        # åˆ†ææ¯ä¸ªæŒ‡æ ‡çš„çŠ¶æ€
        for indicator_name, patterns in COMPLETE_INDICATOR_PATTERNS_MAP.items():
            if not isinstance(patterns, dict):
                continue
                
            pattern_count = len(patterns)
            priority = self.get_indicator_priority(indicator_name)
            implementation_status = self.check_indicator_implementation(indicator_name)
            
            indicator_info = {
                'name': indicator_name,
                'pattern_count': pattern_count,
                'priority': priority,
                'has_implementation': implementation_status['has_implementation'],
                'registry_patterns_count': implementation_status['patterns_count'],
                'module_path': implementation_status['module_path'],
                'error': implementation_status['error']
            }
            
            # åˆ†ç±»æŒ‡æ ‡
            if implementation_status['has_implementation']:
                if implementation_status['patterns_count'] > 0:
                    analysis_result['migrated_indicators'].append(indicator_info)
                    # å¦‚æœåœ¨é›†ä¸­å¼æ˜ å°„ä¸­è¿˜æœ‰å®šä¹‰ï¼Œåˆ™ä¸ºé‡å¤
                    if pattern_count > 0:
                        analysis_result['duplicate_indicators'].append(indicator_info)
                else:
                    analysis_result['unmigrated_indicators'].append(indicator_info)
            else:
                analysis_result['unmigrated_indicators'].append(indicator_info)
            
            # ç»Ÿè®¡ä¼˜å…ˆçº§åˆ†å¸ƒ
            if priority not in analysis_result['priority_distribution']:
                analysis_result['priority_distribution'][priority] = []
            analysis_result['priority_distribution'][priority].append(indicator_info)
        
        return analysis_result
    
    def generate_migration_recommendations(self, analysis_result: dict) -> list:
        """ç”Ÿæˆè¿ç§»å»ºè®®"""
        recommendations = []
        
        # 1. æ¸…ç†é‡å¤å®šä¹‰çš„å»ºè®®
        if analysis_result['duplicate_indicators']:
            recommendations.append({
                'type': 'cleanup_duplicates',
                'priority': 'HIGH',
                'title': 'æ¸…ç†é‡å¤å®šä¹‰',
                'description': f"ç§»é™¤{len(analysis_result['duplicate_indicators'])}ä¸ªå·²è¿ç§»æŒ‡æ ‡çš„é‡å¤å®šä¹‰",
                'indicators': [ind['name'] for ind in analysis_result['duplicate_indicators']],
                'estimated_effort': 'LOW'
            })
        
        # 2. æŒ‰ä¼˜å…ˆçº§ç”Ÿæˆè¿ç§»å»ºè®®
        priority_order = ['P0', 'P1', 'P2', 'P3']
        for priority in priority_order:
            if priority in analysis_result['priority_distribution']:
                unmigrated_in_priority = [
                    ind for ind in analysis_result['priority_distribution'][priority]
                    if not ind['has_implementation'] or ind['registry_patterns_count'] == 0
                ]
                
                if unmigrated_in_priority:
                    priority_names = {
                        'P0': 'æ ¸å¿ƒæŒ‡æ ‡',
                        'P1': 'é‡è¦æŒ‡æ ‡',
                        'P2': 'å¸¸ç”¨æŒ‡æ ‡',
                        'P3': 'ä¸“ä¸šæŒ‡æ ‡'
                    }
                    
                    recommendations.append({
                        'type': 'migrate_indicators',
                        'priority': priority,
                        'title': f'è¿ç§»{priority_names[priority]}',
                        'description': f"è¿ç§»{len(unmigrated_in_priority)}ä¸ª{priority_names[priority]}åˆ°PatternRegistry",
                        'indicators': [ind['name'] for ind in unmigrated_in_priority],
                        'estimated_effort': 'MEDIUM' if len(unmigrated_in_priority) <= 3 else 'HIGH'
                    })
        
        return recommendations

def main():
    """ä¸»å‡½æ•°"""
    print("å¼€å§‹åˆ†æé›†ä¸­å¼æ˜ å°„çŠ¶æ€...")
    
    analyzer = CentralizedMappingAnalyzer()
    
    # åˆ†æé›†ä¸­å¼æ˜ å°„
    analysis_result = analyzer.analyze_centralized_mapping()
    
    # æ˜¾ç¤ºåˆ†æç»“æœ
    print(f"\nğŸ“ˆ åˆ†æç»“æœè¯¦æƒ…:")
    print(f"   å·²è¿ç§»æŒ‡æ ‡: {len(analysis_result['migrated_indicators'])}")
    print(f"   é‡å¤å®šä¹‰æŒ‡æ ‡: {len(analysis_result['duplicate_indicators'])}")
    print(f"   æœªè¿ç§»æŒ‡æ ‡: {len(analysis_result['unmigrated_indicators'])}")
    
    # æ˜¾ç¤ºé‡å¤å®šä¹‰çš„æŒ‡æ ‡
    if analysis_result['duplicate_indicators']:
        print(f"\nâš ï¸ å‘ç°{len(analysis_result['duplicate_indicators'])}ä¸ªé‡å¤å®šä¹‰çš„æŒ‡æ ‡:")
        for ind in analysis_result['duplicate_indicators']:
            print(f"   - {ind['name']} ({ind['priority']}): é›†ä¸­å¼æ˜ å°„{ind['pattern_count']}ä¸ªå½¢æ€, "
                  f"PatternRegistry{ind['registry_patterns_count']}ä¸ªå½¢æ€")
    
    # æ˜¾ç¤ºæœªè¿ç§»æŒ‡æ ‡æŒ‰ä¼˜å…ˆçº§åˆ†å¸ƒ
    print(f"\nğŸ“‹ æœªè¿ç§»æŒ‡æ ‡æŒ‰ä¼˜å…ˆçº§åˆ†å¸ƒ:")
    for priority in ['P0', 'P1', 'P2', 'P3', 'P4', 'P5', 'P6']:
        if priority in analysis_result['priority_distribution']:
            unmigrated = [ind for ind in analysis_result['priority_distribution'][priority]
                         if not ind['has_implementation'] or ind['registry_patterns_count'] == 0]
            if unmigrated:
                priority_names = {
                    'P0': 'æ ¸å¿ƒæŒ‡æ ‡', 'P1': 'é‡è¦æŒ‡æ ‡', 'P2': 'å¸¸ç”¨æŒ‡æ ‡', 'P3': 'ä¸“ä¸šæŒ‡æ ‡',
                    'P4': 'ZXMç³»åˆ—', 'P5': 'ç³»ç»Ÿåˆ†æ', 'P6': 'å…¶ä»–æŒ‡æ ‡'
                }
                print(f"   {priority} ({priority_names.get(priority, 'å…¶ä»–')}): {len(unmigrated)}ä¸ª")
                for ind in unmigrated:
                    print(f"     - {ind['name']} ({ind['pattern_count']}ä¸ªå½¢æ€)")
    
    # ç”Ÿæˆè¿ç§»å»ºè®®
    recommendations = analyzer.generate_migration_recommendations(analysis_result)
    
    print(f"\nğŸ¯ è¿ç§»å»ºè®® (å…±{len(recommendations)}é¡¹):")
    for i, rec in enumerate(recommendations, 1):
        print(f"{i}. {rec['title']} ({rec['priority']}ä¼˜å…ˆçº§)")
        print(f"   æè¿°: {rec['description']}")
        print(f"   å·¥ä½œé‡: {rec['estimated_effort']}")
        print(f"   æ¶‰åŠæŒ‡æ ‡: {', '.join(rec['indicators'][:5])}")
        if len(rec['indicators']) > 5:
            print(f"   (è¿˜æœ‰{len(rec['indicators']) - 5}ä¸ª...)")
        print()
    
    print("âœ… é›†ä¸­å¼æ˜ å°„çŠ¶æ€åˆ†æå®Œæˆï¼")
    
    return analysis_result

if __name__ == "__main__":
    result = main()
    sys.exit(0)
