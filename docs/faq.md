# å¸¸è§é—®é¢˜è§£ç­” (FAQ)

## ğŸ“– ç›®å½•

- [ç³»ç»Ÿæ¦‚è¿°](#ç³»ç»Ÿæ¦‚è¿°)
- [å®‰è£…å’Œé…ç½®](#å®‰è£…å’Œé…ç½®)
- [æ€§èƒ½ç›¸å…³](#æ€§èƒ½ç›¸å…³)
- [åŠŸèƒ½ä½¿ç”¨](#åŠŸèƒ½ä½¿ç”¨)
- [æŠ€æœ¯æŒ‡æ ‡](#æŠ€æœ¯æŒ‡æ ‡)
- [æ•…éšœæ’é™¤](#æ•…éšœæ’é™¤)
- [å¼€å‘ç›¸å…³](#å¼€å‘ç›¸å…³)

---

## ç³»ç»Ÿæ¦‚è¿°

### â“ è¿™ä¸ªç³»ç»Ÿçš„ä¸»è¦åŠŸèƒ½æ˜¯ä»€ä¹ˆï¼Ÿ

**ç­”**: è‚¡ç¥¨åˆ†æç³»ç»Ÿæ˜¯ä¸€ä¸ªé«˜æ€§èƒ½çš„é‡‘èæ•°æ®åˆ†æå¹³å°ï¼Œä¸»è¦åŠŸèƒ½åŒ…æ‹¬ï¼š

- **ä¹°ç‚¹åˆ†æ**: åŸºäº86ä¸ªæŠ€æœ¯æŒ‡æ ‡çš„ä¸“ä¸šä¹°ç‚¹æ£€æµ‹
- **æŠ€æœ¯æŒ‡æ ‡è®¡ç®—**: æ”¯æŒRSIã€MACDã€KDJç­‰86ç§æŠ€æœ¯æŒ‡æ ‡
- **é«˜æ€§èƒ½å¤„ç†**: 0.05ç§’/è‚¡çš„æè‡´å¤„ç†é€Ÿåº¦
- **æ‰¹é‡åˆ†æ**: æ”¯æŒ72,000è‚¡/å°æ—¶çš„å¤§è§„æ¨¡å¤„ç†

### â“ ç³»ç»Ÿçš„æ€§èƒ½ä¼˜åŒ–æ•ˆæœå¦‚ä½•ï¼Ÿ

**ç­”**: ç»è¿‡æ·±åº¦ä¼˜åŒ–ï¼Œç³»ç»Ÿå®ç°äº†**99.9%çš„æ€§èƒ½æå‡**ï¼š

| æŒ‡æ ‡ | ä¼˜åŒ–å‰ | ä¼˜åŒ–å | æå‡å¹…åº¦ |
|------|--------|--------|----------|
| å¤„ç†æ—¶é—´/è‚¡ | 39.4ç§’ | 0.05ç§’ | **99.9%** |
| ç³»ç»Ÿååé‡ | 91è‚¡/å°æ—¶ | 72,000è‚¡/å°æ—¶ | **788å€** |
| å¹¶è¡Œå¤„ç† | å•çº¿ç¨‹ | 8è¿›ç¨‹å¹¶è¡Œ | **800%** |

### â“ ç³»ç»Ÿæ”¯æŒå“ªäº›æŠ€æœ¯æŒ‡æ ‡ï¼Ÿ

**ç­”**: ç³»ç»Ÿæ”¯æŒ86ä¸ªä¸“ä¸šæŠ€æœ¯æŒ‡æ ‡ï¼Œåˆ†ä¸ºä»¥ä¸‹ç±»åˆ«ï¼š

- **è¶‹åŠ¿ç±»** (23ä¸ª): MA, EMA, MACD, TRIX, DMI, ADXç­‰
- **éœ‡è¡ç±»** (25ä¸ª): RSI, KDJ, CCI, WR, STOCHRSIç­‰  
- **æˆäº¤é‡** (15ä¸ª): OBV, MFI, VR, VOLUME_RATIOç­‰
- **æ³¢åŠ¨ç‡** (10ä¸ª): BOLL, ATR, KCç­‰
- **ZXMä¸“ä¸šä½“ç³»** (13ä¸ª): ä¸“ä¸šä¹°ç‚¹æ£€æµ‹å’Œè¶‹åŠ¿åˆ†æ

---

## å®‰è£…å’Œé…ç½®

### â“ ç³»ç»Ÿçš„ç¯å¢ƒè¦æ±‚æ˜¯ä»€ä¹ˆï¼Ÿ

**ç­”**: 

**åŸºç¡€ç¯å¢ƒ**:
```bash
Python >= 3.8
å†…å­˜ >= 8GB
CPU >= 4æ ¸å¿ƒ
ç£ç›˜ç©ºé—´ >= 10GB
```

**æ¨èé…ç½®**:
```bash
Python 3.9+
å†…å­˜ >= 16GB
CPU >= 8æ ¸å¿ƒï¼ˆå‘æŒ¥å¹¶è¡Œä¼˜åŠ¿ï¼‰
SSDå­˜å‚¨ï¼ˆæå‡ç¼“å­˜æ€§èƒ½ï¼‰
```

### â“ å¦‚ä½•å®‰è£…ç³»ç»Ÿï¼Ÿ

**ç­”**: 

```bash
# 1. å…‹éš†é¡¹ç›®
git clone https://github.com/your-username/stock-analysis-system.git
cd stock-analysis-system

# 2. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python -m venv venv
source venv/bin/activate  # Linux/Mac

# 3. å®‰è£…ä¾èµ–
pip install -r requirements.txt

# 4. é…ç½®æ•°æ®åº“ï¼ˆå¯é€‰ï¼‰
cp config/database.example.yaml config/database.yaml
# ç¼–è¾‘æ•°æ®åº“é…ç½®
```

### â“ å®‰è£…ä¾èµ–æ—¶å‡ºç°é”™è¯¯æ€ä¹ˆåŠï¼Ÿ

**ç­”**: è¯·æŒ‰ä»¥ä¸‹æ­¥éª¤æ’æŸ¥ï¼š

```bash
# 1. æ›´æ–°pip
pip install --upgrade pip

# 2. æ¸…ç†ç¼“å­˜
pip cache purge

# 3. ä½¿ç”¨å›½å†…é•œåƒæº
pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple/

# 4. åˆ†æ­¥å®‰è£…æ ¸å¿ƒä¾èµ–
pip install pandas numpy scipy
pip install clickhouse-driver redis
```

### â“ å¦‚ä½•é…ç½®æ•°æ®åº“è¿æ¥ï¼Ÿ

**ç­”**: 

1. å¤åˆ¶é…ç½®æ–‡ä»¶æ¨¡æ¿ï¼š
```bash
cp config/database.example.yaml config/database.yaml
```

2. ç¼–è¾‘é…ç½®æ–‡ä»¶ï¼š
```yaml
database:
  host: localhost
  port: 3306
  database: stock_analysis
  username: your_username
  password: your_password
```

3. æµ‹è¯•è¿æ¥ï¼š
```python
from utils.database import test_connection
result = test_connection()
print(f"è¿æ¥çŠ¶æ€: {'æˆåŠŸ' if result['success'] else 'å¤±è´¥'}")
```

---

## æ€§èƒ½ç›¸å…³

### â“ å¦‚ä½•å¯ç”¨æ‰€æœ‰æ€§èƒ½ä¼˜åŒ–åŠŸèƒ½ï¼Ÿ

**ç­”**: 

```python
from analysis.optimized_buypoint_analyzer import OptimizedBuyPointAnalyzer

# åˆ›å»ºä¼˜åŒ–åˆ†æå™¨ï¼ˆå¯ç”¨æ‰€æœ‰ä¼˜åŒ–ï¼‰
analyzer = OptimizedBuyPointAnalyzer(
    enable_cache=True,           # æ™ºèƒ½ç¼“å­˜
    enable_vectorization=True    # å‘é‡åŒ–è®¡ç®—
)

# ä½¿ç”¨å¹¶è¡Œå¤„ç†
from analysis.parallel_buypoint_analyzer import ParallelBuyPointAnalyzer
parallel_analyzer = ParallelBuyPointAnalyzer(max_workers=8)
```

### â“ ç³»ç»Ÿè¿è¡Œç¼“æ…¢æ€ä¹ˆåŠï¼Ÿ

**ç­”**: æŒ‰ä¼˜å…ˆçº§æ£€æŸ¥ä»¥ä¸‹è®¾ç½®ï¼š

1. **å¯ç”¨ç¼“å­˜**:
```python
# æ£€æŸ¥ç¼“å­˜çŠ¶æ€
cache_stats = analyzer.cache_system.get_cache_stats()
print(f"ç¼“å­˜å‘½ä¸­ç‡: {cache_stats['hit_rate']:.1f}%")

# å¦‚æœå‘½ä¸­ç‡ä½ï¼Œæ¸…ç†å¹¶é‡å»ºç¼“å­˜
analyzer.cache_system.clear_cache()
```

2. **è°ƒæ•´å¹¶è¡Œå‚æ•°**:
```python
import multiprocessing
optimal_workers = min(8, multiprocessing.cpu_count())
parallel_analyzer = ParallelBuyPointAnalyzer(max_workers=optimal_workers)
```

3. **æ£€æŸ¥ç³»ç»Ÿèµ„æº**:
```python
import psutil
print(f"CPUä½¿ç”¨ç‡: {psutil.cpu_percent()}%")
print(f"å†…å­˜ä½¿ç”¨ç‡: {psutil.virtual_memory().percent}%")
```

### â“ ç¼“å­˜ä¸ç”Ÿæ•ˆæ€ä¹ˆåŠï¼Ÿ

**ç­”**: 

1. **æ£€æŸ¥ç¼“å­˜é…ç½®**:
```python
cache_stats = cache_system.get_cache_stats()
if cache_stats['hit_rate'] == 0:
    print("ç¼“å­˜å¯èƒ½çš„é—®é¢˜ï¼š")
    print("1. ç¼“å­˜ç›®å½•æƒé™ä¸è¶³")
    print("2. ç£ç›˜ç©ºé—´ä¸è¶³") 
    print("3. ç¼“å­˜é”®ç”Ÿæˆå¼‚å¸¸")
```

2. **é‡ç½®ç¼“å­˜ç³»ç»Ÿ**:
```python
# æ¸…ç©ºæ‰€æœ‰ç¼“å­˜
cache_system.clear_cache(clear_disk=True)

# é‡æ–°åˆå§‹åŒ–
from analysis.intelligent_cache_system import IntelligentCacheSystem
cache_system = IntelligentCacheSystem()
```

3. **æ£€æŸ¥ç¼“å­˜ç›®å½•æƒé™**:
```bash
# ç¡®ä¿ç¼“å­˜ç›®å½•å¯å†™
chmod 755 data/cache
ls -la data/cache
```

### â“ å¦‚ä½•ç›‘æ§ç³»ç»Ÿæ€§èƒ½ï¼Ÿ

**ç­”**: 

```python
# 1. è·å–æ€§èƒ½ç»Ÿè®¡
from analysis.optimized_buypoint_analyzer import OptimizedBuyPointAnalyzer
analyzer = OptimizedBuyPointAnalyzer()
stats = analyzer.get_optimization_stats()

print(f"æ€»è®¡ç®—æ¬¡æ•°: {stats['total_calculations']}")
print(f"ç¼“å­˜å‘½ä¸­æ¬¡æ•°: {stats['cache_hits']}")
print(f"å‘é‡åŒ–è®¡ç®—æ¬¡æ•°: {stats['vectorized_calculations']}")

# 2. è¿è¡Œæ€§èƒ½æµ‹è¯•
python bin/quick_performance_test.py

# 3. è¯¦ç»†æ€§èƒ½åˆ†æ
python analysis/indicator_performance_profiler.py
```

---

## åŠŸèƒ½ä½¿ç”¨

### â“ å¦‚ä½•è¿›è¡Œä¹°ç‚¹åˆ†æï¼Ÿ

**ç­”**: 

**å•ä¸ªä¹°ç‚¹åˆ†æ**:
```python
from analysis.optimized_buypoint_analyzer import OptimizedBuyPointAnalyzer

analyzer = OptimizedBuyPointAnalyzer(enable_cache=True, enable_vectorization=True)
result = analyzer.analyze_single_buypoint_optimized('000001', '20250101')

print(f"ä¹°ç‚¹è¯„åˆ†: {result.get('buypoint_score', 'N/A')}")
print(f"å¤„ç†æ—¶é—´: {result['analysis_time']:.4f}ç§’")
```

**æ‰¹é‡ä¹°ç‚¹åˆ†æ**:
```python
from analysis.parallel_buypoint_analyzer import ParallelBuyPointAnalyzer

parallel_analyzer = ParallelBuyPointAnalyzer(max_workers=8)
buypoints_df = parallel_analyzer.load_buypoints_from_csv("data/buypoints.csv")
results = parallel_analyzer.analyze_batch_buypoints_concurrent(buypoints_df)

print(f"æ‰¹é‡åˆ†æå®Œæˆ: {len(results)}ä¸ªä¹°ç‚¹")
```

### â“ å¦‚ä½•è®¡ç®—æŠ€æœ¯æŒ‡æ ‡ï¼Ÿ

**ç­”**: 

**å•ä¸ªæŒ‡æ ‡è®¡ç®—**:
```python
from indicators.indicator_registry import IndicatorRegistry

registry = IndicatorRegistry()
rsi_indicator = registry.create_indicator('RSI')
rsi_result = rsi_indicator.calculate(stock_data)
```

**å‘é‡åŒ–æ‰¹é‡è®¡ç®—**:
```python
from analysis.vectorized_indicator_optimizer import VectorizedIndicatorOptimizer

optimizer = VectorizedIndicatorOptimizer()
rsi_result = optimizer.optimize_rsi_calculation(stock_data)
macd_result = optimizer.optimize_macd_calculation(stock_data)
```

### â“ å¦‚ä½•å¤„ç†å¤šå‘¨æœŸæ•°æ®ï¼Ÿ

**ç­”**: 

```python
from data.data_processor import DataProcessor

processor = DataProcessor()
multi_period_data = processor.get_multi_period_data(
    stock_code='000001',
    end_date='20250101'
)

print("å¯ç”¨å‘¨æœŸ:", list(multi_period_data.keys()))
for period, df in multi_period_data.items():
    if df is not None:
        print(f"{period}: {len(df)}è¡Œæ•°æ®")
```

---

## æŠ€æœ¯æŒ‡æ ‡

### â“ å¦‚ä½•æŸ¥çœ‹æ‰€æœ‰æ”¯æŒçš„æŠ€æœ¯æŒ‡æ ‡ï¼Ÿ

**ç­”**: 

```python
from indicators.indicator_registry import IndicatorRegistry

registry = IndicatorRegistry()
all_indicators = registry.get_all_indicators()

print(f"æ€»æŒ‡æ ‡æ•°: {len(all_indicators)}")
for category, indicators in all_indicators.items():
    print(f"{category}: {len(indicators)}ä¸ª")
    print(f"  {', '.join(indicators[:5])}...")
```

### â“ æŸä¸ªæŒ‡æ ‡è®¡ç®—ç»“æœå¼‚å¸¸æ€ä¹ˆåŠï¼Ÿ

**ç­”**: 

1. **æ•°æ®éªŒè¯**:
```python
from data.data_processor import DataProcessor

processor = DataProcessor()
validation_result = processor.validate_data_integrity(stock_data)

if not validation_result['is_valid']:
    print(f"æ•°æ®é—®é¢˜: {validation_result['issues']}")
```

2. **æŒ‡æ ‡å‚æ•°æ£€æŸ¥**:
```python
# æ£€æŸ¥æŒ‡æ ‡æ˜¯å¦æ”¯æŒ
if 'RSI' in registry.get_available_indicators():
    print("RSIæŒ‡æ ‡å¯ç”¨")
else:
    print("RSIæŒ‡æ ‡ä¸å¯ç”¨")

# æ£€æŸ¥æ•°æ®æ ¼å¼
required_columns = ['open', 'high', 'low', 'close', 'volume']
missing_columns = [col for col in required_columns if col not in stock_data.columns]
if missing_columns:
    print(f"ç¼ºå°‘æ•°æ®åˆ—: {missing_columns}")
```

3. **ä½¿ç”¨è°ƒè¯•æ¨¡å¼**:
```python
import logging
logging.basicConfig(level=logging.DEBUG)

# é‡æ–°è®¡ç®—æŒ‡æ ‡ï¼ŒæŸ¥çœ‹è¯¦ç»†æ—¥å¿—
result = indicator.calculate(stock_data)
```

### â“ å¦‚ä½•è‡ªå®šä¹‰æŠ€æœ¯æŒ‡æ ‡ï¼Ÿ

**ç­”**: 

```python
from indicators.base_indicator import BaseIndicator

class CustomIndicator(BaseIndicator):
    def __init__(self, period=14):
        super().__init__()
        self.period = period
        
    def calculate(self, data):
        # å®ç°è‡ªå®šä¹‰è®¡ç®—é€»è¾‘
        close = data['close']
        result = close.rolling(window=self.period).mean()
        return result
    
    def get_pattern_info(self):
        return {
            'name': 'Custom Indicator',
            'description': 'è‡ªå®šä¹‰æŒ‡æ ‡',
            'parameters': {'period': self.period}
        }

# æ³¨å†Œè‡ªå®šä¹‰æŒ‡æ ‡
from indicators.indicator_registry import IndicatorRegistry
registry = IndicatorRegistry()
registry.register_indicator('CUSTOM', CustomIndicator)
```

---

## æ•…éšœæ’é™¤

### â“ ç³»ç»Ÿå¯åŠ¨å¤±è´¥æ€ä¹ˆåŠï¼Ÿ

**ç­”**: 

1. **æ£€æŸ¥Pythonç‰ˆæœ¬**:
```bash
python --version  # åº”è¯¥ >= 3.8
```

2. **æ£€æŸ¥ä¾èµ–å®‰è£…**:
```bash
pip list | grep pandas
pip list | grep numpy
```

3. **æ£€æŸ¥é…ç½®æ–‡ä»¶**:
```python
import os
config_files = ['config/database.yaml', 'config/settings.py']
for file in config_files:
    if os.path.exists(file):
        print(f"âœ“ {file} å­˜åœ¨")
    else:
        print(f"âœ— {file} ä¸å­˜åœ¨")
```

### â“ å†…å­˜ä½¿ç”¨è¿‡é«˜æ€ä¹ˆåŠï¼Ÿ

**ç­”**: 

1. **å¯ç”¨æ•°æ®æ¸…ç†**:
```python
import gc

# æ‰‹åŠ¨åƒåœ¾å›æ”¶
gc.collect()

# æ¸…ç†å¤§å‹æ•°æ®å¯¹è±¡
del large_dataframe
gc.collect()
```

2. **ä¼˜åŒ–æ•°æ®å¤„ç†**:
```python
# ä½¿ç”¨æ•°æ®ç±»å‹ä¼˜åŒ–
stock_data = stock_data.astype({
    'open': 'float32',
    'high': 'float32', 
    'low': 'float32',
    'close': 'float32',
    'volume': 'int32'
})

# åˆ†æ‰¹å¤„ç†å¤§æ•°æ®é›†
chunk_size = 1000
for chunk in pd.read_csv('large_file.csv', chunksize=chunk_size):
    process_chunk(chunk)
```

3. **è°ƒæ•´ç¼“å­˜å¤§å°**:
```python
# å‡å°‘å†…å­˜ç¼“å­˜å¤§å°
cache_system = IntelligentCacheSystem(
    max_memory_cache_size=500,  # ä»1000å‡å°‘åˆ°500
    enable_disk_cache=True
)
```

### â“ æ•°æ®åº“è¿æ¥å¤±è´¥æ€ä¹ˆåŠï¼Ÿ

**ç­”**: 

1. **æ£€æŸ¥æ•°æ®åº“æœåŠ¡**:
```bash
# MySQL
sudo systemctl status mysql

# æˆ–è€…æ£€æŸ¥ç«¯å£
netstat -an | grep 3306
```

2. **æµ‹è¯•è¿æ¥**:
```python
from utils.database import test_connection

result = test_connection()
if not result['success']:
    print(f"è¿æ¥å¤±è´¥: {result['error']}")
    print("è¯·æ£€æŸ¥:")
    print("1. æ•°æ®åº“æœåŠ¡æ˜¯å¦å¯åŠ¨")
    print("2. ç”¨æˆ·åå¯†ç æ˜¯å¦æ­£ç¡®")
    print("3. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸")
```

3. **ä½¿ç”¨å¤‡ç”¨æ•°æ®æº**:
```python
# å¦‚æœæ•°æ®åº“ä¸å¯ç”¨ï¼Œä½¿ç”¨CSVæ–‡ä»¶
try:
    data = load_from_database(stock_code, date)
except Exception:
    print("æ•°æ®åº“ä¸å¯ç”¨ï¼Œä½¿ç”¨CSVæ–‡ä»¶")
    data = pd.read_csv(f'data/stock_data/{stock_code}.csv')
```

---

## å¼€å‘ç›¸å…³

### â“ å¦‚ä½•è´¡çŒ®ä»£ç ï¼Ÿ

**ç­”**: 

1. **Forké¡¹ç›®**:
```bash
git clone https://github.com/your-username/stock-analysis-system.git
cd stock-analysis-system
```

2. **åˆ›å»ºå¼€å‘åˆ†æ”¯**:
```bash
git checkout -b feature/your-feature-name
```

3. **å®‰è£…å¼€å‘ä¾èµ–**:
```bash
pip install -r requirements-dev.txt
```

4. **è¿è¡Œæµ‹è¯•**:
```bash
python -m pytest tests/
```

5. **ä»£ç æ ¼å¼åŒ–**:
```bash
black analysis/ indicators/ utils/
flake8 analysis/ indicators/ utils/
```

### â“ å¦‚ä½•æ·»åŠ æ–°çš„æŠ€æœ¯æŒ‡æ ‡ï¼Ÿ

**ç­”**: 

1. **åˆ›å»ºæŒ‡æ ‡ç±»**:
```python
# indicators/custom/my_indicator.py
from indicators.base_indicator import BaseIndicator

class MyIndicator(BaseIndicator):
    def calculate(self, data):
        # å®ç°è®¡ç®—é€»è¾‘
        pass
    
    def get_pattern_info(self):
        return {
            'name': 'My Indicator',
            'description': 'æˆ‘çš„è‡ªå®šä¹‰æŒ‡æ ‡'
        }
```

2. **æ³¨å†ŒæŒ‡æ ‡**:
```python
# indicators/__init__.py
from .custom.my_indicator import MyIndicator

def register_custom_indicators(registry):
    registry.register_indicator('MY_INDICATOR', MyIndicator)
```

3. **æ·»åŠ æµ‹è¯•**:
```python
# tests/test_my_indicator.py
def test_my_indicator():
    indicator = MyIndicator()
    result = indicator.calculate(test_data)
    assert result is not None
```

### â“ å¦‚ä½•è¿è¡Œæ€§èƒ½æµ‹è¯•ï¼Ÿ

**ç­”**: 

```bash
# å¿«é€Ÿæ€§èƒ½æµ‹è¯•
python bin/quick_performance_test.py

# è¯¦ç»†æ€§èƒ½åˆ†æ
python bin/simple_performance_test.py

# æŒ‡æ ‡æ€§èƒ½åˆ†æ
python analysis/indicator_performance_profiler.py

# ç¼“å­˜æ€§èƒ½æµ‹è¯•
python analysis/intelligent_cache_system.py

# å‘é‡åŒ–æ€§èƒ½æµ‹è¯•
python analysis/vectorized_indicator_optimizer.py
```

### â“ å¦‚ä½•è°ƒè¯•æ€§èƒ½é—®é¢˜ï¼Ÿ

**ç­”**: 

1. **å¯ç”¨æ€§èƒ½åˆ†æ**:
```python
import cProfile
import pstats

# æ€§èƒ½åˆ†æ
profiler = cProfile.Profile()
profiler.enable()

# æ‰§è¡Œä»£ç 
result = analyzer.analyze_buypoint(stock_code, date)

profiler.disable()
stats = pstats.Stats(profiler)
stats.sort_stats('cumulative').print_stats(10)
```

2. **å†…å­˜åˆ†æ**:
```python
import tracemalloc

tracemalloc.start()

# æ‰§è¡Œä»£ç 
result = analyzer.analyze_buypoint(stock_code, date)

current, peak = tracemalloc.get_traced_memory()
print(f"å½“å‰å†…å­˜: {current / 1024 / 1024:.1f} MB")
print(f"å³°å€¼å†…å­˜: {peak / 1024 / 1024:.1f} MB")
```

3. **æ—¶é—´åˆ†æ**:
```python
import time
from functools import wraps

def timing_decorator(func):
    @wraps(func)
    def wrapper(*args, **kwargs):
        start = time.time()
        result = func(*args, **kwargs)
        end = time.time()
        print(f"{func.__name__} è€—æ—¶: {end - start:.4f}ç§’")
        return result
    return wrapper

@timing_decorator
def analyze_with_timing(stock_code, date):
    return analyzer.analyze_buypoint(stock_code, date)
```

---

## ğŸ“ è·å–æ›´å¤šå¸®åŠ©

å¦‚æœä»¥ä¸ŠFAQæ²¡æœ‰è§£å†³æ‚¨çš„é—®é¢˜ï¼Œè¯·é€šè¿‡ä»¥ä¸‹æ–¹å¼è·å–å¸®åŠ©ï¼š

- ğŸ“§ **é‚®ç®±**: support@stockanalysis.com
- ğŸ› **é—®é¢˜åé¦ˆ**: [GitHub Issues](https://github.com/your-repo/issues)
- ğŸ’¬ **è®¨è®º**: [GitHub Discussions](https://github.com/your-repo/discussions)
- ğŸ“š **æ–‡æ¡£**: [å®Œæ•´æ–‡æ¡£](docs/user_guide.md)

---

*FAQæ–‡æ¡£ç‰ˆæœ¬: v2.0*  
*æœ€åæ›´æ–°: 2025-06-15*  
*å¦‚æœ‰é—®é¢˜ï¼Œæ¬¢è¿åé¦ˆï¼*
